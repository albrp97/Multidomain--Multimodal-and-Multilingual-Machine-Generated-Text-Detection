{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback,AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Variables'''\n",
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "\n",
    "SAMPLES_TO_TRAIN=5000\n",
    "\n",
    "random_seed=0\n",
    "LEARNING_RATE=2e-5\n",
    "BATCH_SIZE=16\n",
    "EPOCHS=3\n",
    "WEIGHT_DECAY=0.01\n",
    "\n",
    "PATIENCE=2\n",
    "id2label = {0: \"human\", 1: \"machine\"}\n",
    "label2id = {\"human\": 0, \"machine\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29495 entries, 44964 to 92357\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      29495 non-null  object\n",
      " 1   label     29495 non-null  int64 \n",
      " 2   model     29495 non-null  object\n",
      " 3   id        29495 non-null  int64 \n",
      " 4   language  29495 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "\n",
      "label\n",
      "0    14764\n",
      "1    14731\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "human      14764\n",
      "chatGPT     9392\n",
      "davinci     3499\n",
      "cohere       638\n",
      "bloomz       622\n",
      "dolly        580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "language\n",
      "bulgarian     5899\n",
      "chinese       5899\n",
      "english       5899\n",
      "indonesian    5899\n",
      "urdu          5899\n",
      "Name: count, dtype: int64\n",
      "                                                     text  label    model  \\\n",
      "34391   This article provides an analysis of the conve...      1  davinci   \n",
      "168430    The combined all-electron and two-step appro...      0    human   \n",
      "53494   Jakarta, CNN Indonesia -- Kabar bahagia datang...      1  chatGPT   \n",
      "53378   Jakarta, CNN Indonesia -- Pelabuhan Tanjung Em...      1  chatGPT   \n",
      "53145   Jakarta, CNN Indonesia -- Acara penghargaan mu...      1  chatGPT   \n",
      "\n",
      "            id    language  \n",
      "34391    34391     english  \n",
      "168430  168430     english  \n",
      "53494    53494  indonesian  \n",
      "53378    53378  indonesian  \n",
      "53145    53145  indonesian  \n",
      "\n",
      "Train DataFrame:\n",
      "label\n",
      "1    1507\n",
      "0    1493\n",
      "Name: count, dtype: int64\n",
      "Total entries (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "'''Preparing Data'''\n",
    "\n",
    "df= pd.read_json('datasets/subtaskA_train_multilingual.jsonl', lines=True)\n",
    "\n",
    "# We convert source to languaje\n",
    "df = df.rename(columns={'source': 'language'})\n",
    "non_language_sources = ['wikihow', 'wikipedia', 'reddit', 'arxiv', 'peerread']\n",
    "df['language'] = df['language'].replace(non_language_sources, 'english')\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(df.drop('language', axis=1), df['language'])\n",
    "df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "print(f'Original dataset')\n",
    "print(df.info())\n",
    "print(f'''\\n{df['label'].value_counts()}''')\n",
    "print(f'''\\n{df['model'].value_counts()}''')\n",
    "print(f'''\\n{df['language'].value_counts()}''')\n",
    "\n",
    "print(df.sample(5))\n",
    "\n",
    "if SAMPLES_TO_TRAIN>0:\n",
    "    df=df.sample(SAMPLES_TO_TRAIN)\n",
    "train_df, val_df = train_test_split(df, test_size=0.4, stratify=df['label'], random_state=random_seed)\n",
    "val_df, test_df= train_test_split(val_df, test_size=0.5, stratify=val_df['label'], random_state=random_seed)\n",
    "dev_df= pd.read_json('datasets/subtaskA_dev_multilingual.jsonl', lines=True)\n",
    "\n",
    "print(\"\\nTrain DataFrame:\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(f'Total entries {train_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 502/502 [00:00<?, ?B/s] \n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 9.34MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.08M/9.08M [00:00<00:00, 12.3MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<?, ?B/s] \n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.42k/1.42k [00:00<?, ?B/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.11G/1.11G [00:16<00:00, 65.8MB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for XLMRobertaForSequenceClassification:\n\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([20, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([2]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ghiki\\Documents\\GitHub\\Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection\\SubtaskA 2.0\\04 Multilingual Model training copy.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m fn_kwargs[\u001b[39m'\u001b[39m\u001b[39mtokenizer\u001b[39m\u001b[39m'\u001b[39m](examples[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m], truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(MODEL_NAME)     \u001b[39m# put your model here\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     MODEL_NAME, num_labels\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(label2id), id2label\u001b[39m=\u001b[39;49mid2label, label2id\u001b[39m=\u001b[39;49mlabel2id    \u001b[39m# put your model here\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# tokenize data for train/valid\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/04%20Multilingual%20Model%20training%20copy.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m train_dataset\u001b[39m.\u001b[39mmap(preprocess_function, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fn_kwargs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtokenizer\u001b[39m\u001b[39m'\u001b[39m: tokenizer})\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[0;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    565\u001b[0m     )\n\u001b[0;32m    566\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    567\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3180\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3170\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3171\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3173\u001b[0m     (\n\u001b[0;32m   3174\u001b[0m         model,\n\u001b[0;32m   3175\u001b[0m         missing_keys,\n\u001b[0;32m   3176\u001b[0m         unexpected_keys,\n\u001b[0;32m   3177\u001b[0m         mismatched_keys,\n\u001b[0;32m   3178\u001b[0m         offload_index,\n\u001b[0;32m   3179\u001b[0m         error_msgs,\n\u001b[1;32m-> 3180\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[0;32m   3181\u001b[0m         model,\n\u001b[0;32m   3182\u001b[0m         state_dict,\n\u001b[0;32m   3183\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3184\u001b[0m         resolved_archive_file,\n\u001b[0;32m   3185\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   3186\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[0;32m   3187\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[0;32m   3188\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[0;32m   3189\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[0;32m   3190\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[0;32m   3191\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[0;32m   3192\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[0;32m   3193\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[0;32m   3194\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(\u001b[39mgetattr\u001b[39;49m(model, \u001b[39m\"\u001b[39;49m\u001b[39mquantization_method\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m) \u001b[39m==\u001b[39;49m QuantizationMethod\u001b[39m.\u001b[39;49mBITS_AND_BYTES),\n\u001b[0;32m   3195\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[0;32m   3196\u001b[0m     )\n\u001b[0;32m   3198\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[0;32m   3199\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3629\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3625\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msize mismatch\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m error_msg:\n\u001b[0;32m   3626\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m   3627\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3628\u001b[0m         )\n\u001b[1;32m-> 3629\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{\u001b[39;00merror_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3631\u001b[0m \u001b[39mif\u001b[39;00m is_quantized:\n\u001b[0;32m   3632\u001b[0m     unexpected_keys \u001b[39m=\u001b[39m [elem \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m unexpected_keys \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mSCB\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m elem]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for XLMRobertaForSequenceClassification:\n\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([20, 768]) from checkpoint, the shape in current model is torch.Size([2, 768]).\n\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([20]) from checkpoint, the shape in current model is torch.Size([2]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "'''Preparing data'''\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    f1 = precision_recall_fscore_support(labels, preds, average='macro')[2]\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'accuracy': acc,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "dev_dataset = Dataset.from_pandas(dev_df)\n",
    "\n",
    "def preprocess_function(examples, **fn_kwargs):\n",
    "    return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)     # put your model here\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(label2id), id2label=id2label, label2id=label2id    # put your model here\n",
    ")\n",
    "\n",
    "# tokenize data for train/valid\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "dev_dataset = dev_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    ")\n",
    "\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/564 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 33%|███▎      | 188/564 [00:46<01:21,  4.61it/s]Trainer is attempting to log a value of \"[[322, 176], [9, 493]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      " 33%|███▎      | 188/564 [00:52<01:21,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5861284136772156, 'eval_f1': 0.8094274686096137, 'eval_confusion_matrix': [[322, 176], [9, 493]], 'eval_accuracy': 0.815, 'eval_auc': 0.8143290292644683, 'eval_precision': 0.7369207772795217, 'eval_recall': 0.9820717131474104, 'eval_runtime': 5.659, 'eval_samples_per_second': 176.71, 'eval_steps_per_second': 11.133, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 376/564 [01:42<00:39,  4.75it/s]Trainer is attempting to log a value of \"[[449, 49], [16, 486]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      " 67%|██████▋   | 376/564 [01:47<00:39,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25484809279441833, 'eval_f1': 0.9349108930125342, 'eval_confusion_matrix': [[449, 49], [16, 486]], 'eval_accuracy': 0.935, 'eval_auc': 0.9348669578713259, 'eval_precision': 0.908411214953271, 'eval_recall': 0.9681274900398407, 'eval_runtime': 5.5, 'eval_samples_per_second': 181.817, 'eval_steps_per_second': 11.454, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 500/564 [02:22<00:15,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2422, 'learning_rate': 2.269503546099291e-06, 'epoch': 2.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 564/564 [02:37<00:00,  4.70it/s]Trainer is attempting to log a value of \"[[389, 109], [1, 501]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      "100%|██████████| 564/564 [02:43<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5217993259429932, 'eval_f1': 0.8886026314083868, 'eval_confusion_matrix': [[389, 109], [1, 501]], 'eval_accuracy': 0.89, 'eval_auc': 0.8895662330597289, 'eval_precision': 0.8213114754098361, 'eval_recall': 0.99800796812749, 'eval_runtime': 5.6099, 'eval_samples_per_second': 178.257, 'eval_steps_per_second': 11.23, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 564/564 [02:47<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 167.3923, 'train_samples_per_second': 53.766, 'train_steps_per_second': 3.369, 'train_loss': 0.22287737308664524, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=564, training_loss=0.22287737308664524, metrics={'train_runtime': 167.3923, 'train_samples_per_second': 53.766, 'train_steps_per_second': 3.369, 'train_loss': 0.22287737308664524, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 249/250 [00:21<00:00,  9.65it/s]Trainer is attempting to log a value of \"[[898, 1102], [323, 1677]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "100%|██████████| 250/250 [00:21<00:00, 11.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.6140904426574707,\n",
       " 'eval_f1': 0.6297056374198434,\n",
       " 'eval_confusion_matrix': [[898, 1102], [323, 1677]],\n",
       " 'eval_accuracy': 0.64375,\n",
       " 'eval_auc': 0.64375,\n",
       " 'eval_precision': 0.6034544800287873,\n",
       " 'eval_recall': 0.8385,\n",
       " 'eval_runtime': 21.458,\n",
       " 'eval_samples_per_second': 186.411,\n",
       " 'eval_steps_per_second': 11.651,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation=trainer.evaluate(dev_dataset)\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00, 11.27it/s]Trainer is attempting to log a value of \"[[463, 34], [21, 482]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "100%|██████████| 63/63 [00:06<00:00,  9.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22549313306808472,\n",
       " 'eval_f1': 0.9449801378297567,\n",
       " 'eval_confusion_matrix': [[463, 34], [21, 482]],\n",
       " 'eval_accuracy': 0.945,\n",
       " 'eval_auc': 0.9449200171206164,\n",
       " 'eval_precision': 0.9341085271317829,\n",
       " 'eval_recall': 0.9582504970178927,\n",
       " 'eval_runtime': 6.5911,\n",
       " 'eval_samples_per_second': 151.719,\n",
       " 'eval_steps_per_second': 9.558,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''Save'''\n",
    "# import json\n",
    "# trainer.save_model('SavedModels/'+(MODEL_NAME.split('/')[-1])+str(round(SAMPLES_TO_TRAIN/1000))+'k')\n",
    "# with open('SavedModels/'+(MODEL_NAME.split('/')[-1])+str(round(SAMPLES_TO_TRAIN/1000))+'k/metrics.json', 'w') as file:\n",
    "#     json.dump(evaluation, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
