{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from transformers import AutoConfig, RobertaModel, RobertaForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import pandas as pd,os\n",
    "import torch\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pickle\n",
    "from transformers import RobertaConfig, RobertaModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, RobertaModel, RobertaForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from typing import Optional, Union, Tuple\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback,AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textstat.textstat import textstatistics\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_extra_dims):\n",
    "        super().__init__()\n",
    "        total_dims = config.hidden_size+num_extra_dims\n",
    "        self.dense = nn.Linear(total_dims, total_dims)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class CustomSequenceClassification(RobertaForSequenceClassification):\n",
    "\n",
    "    def __init__(self, config, num_extra_dims):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        # might need to rename this depending on the model\n",
    "        self.roberta =  RobertaModel(config)\n",
    "        self.classifier = ClassificationHead(config, num_extra_dims)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        extra_data: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # sequence_output will be (batch_size, seq_length, hidden_size)\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        # additional data should be (batch_size, num_extra_dims)\n",
    "        cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        output = torch.cat((cls_embedding, extra_data), dim=-1)\n",
    "\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = nn.MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      5000 non-null   object\n",
      " 1   label     5000 non-null   int64 \n",
      " 2   model     5000 non-null   object\n",
      " 3   language  5000 non-null   object\n",
      " 4   id        5000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 195.4+ KB\n",
      "None\n",
      "\n",
      "label\n",
      "1    2500\n",
      "0    2500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "bloomz    2500\n",
      "human     2500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "language\n",
      "english    5000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing with bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:01<00:00, 4892.62 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:19<00:00, 32.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with Hello-SimpleAI/chatgpt-detector-roberta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 5467.57 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:19<00:00, 32.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with roberta-base-openai-detector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 5076.68 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:19<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 5341.40 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:19<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:01<00:00, 4959.75 examples/s]\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:10<00:00, 61.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with google/electra-base-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:01<00:00, 4441.17 examples/s]\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 625/625 [00:19<00:00, 32.44it/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:04<00:00, 1085.05 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 17533.92 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:04<00:00, 1110.21 examples/s]\n",
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 29911.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with multidomain-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:25<00:00, 24.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with multidomain-extended-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:25<00:00, 24.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL1 = 'bert-base-uncased'\n",
    "MODEL2 = 'Hello-SimpleAI/chatgpt-detector-roberta'\n",
    "MODEL3 = 'roberta-base-openai-detector'\n",
    "MODEL4 = 'roberta-base'\n",
    "MODEL5 = 'distilbert-base-uncased'\n",
    "MODEL6 = 'google/electra-base-discriminator'\n",
    "\n",
    "MODEL8='multidomain-roberta-base'\n",
    "MODEL9='multidomain-extended-roberta-base'\n",
    "\n",
    "MODEL_PATH1='SavedModels/optimized-bert-base-uncased-22.5k'\n",
    "MODEL_PATH2='SavedModels/optimized-chatgpt-detector-roberta-17.5k'\n",
    "MODEL_PATH3='SavedModels/optimized-roberta-base-openai-detector-12k'\n",
    "MODEL_PATH4='SavedModels/optimized-roberta-base-0.5k'\n",
    "MODEL_PATH5='SavedModels/optimized-distilbert-base-uncased-15k'\n",
    "MODEL_PATH6='SavedModels/optimized-electra-base-discriminator-6k'\n",
    "\n",
    "MODEL_PATH8='SavedModels/optimized-multidomain-roberta-base-1k'\n",
    "MODEL_PATH9='SavedModels/optimized-multidomain-extended-robera-base-0.8k'\n",
    "\n",
    "'''Preparing data'''\n",
    "\n",
    "df = pd.read_json('datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "\n",
    "df = df.rename(columns={'source': 'language'})\n",
    "non_language_sources = ['wikihow', 'wikipedia', 'reddit', 'arxiv', 'peerread']\n",
    "df['language'] = df['language'].replace(non_language_sources, 'english')\n",
    "\n",
    "print(f'Original dataset')\n",
    "print(df.info())\n",
    "\n",
    "print(f'''\\n{df['label'].value_counts()}''')\n",
    "print(f'''\\n{df['model'].value_counts()}''')\n",
    "print(f'''\\n{df['language'].value_counts()}''')\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "test_df=df\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "def getPrediction(model_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    id2label = {0: \"human\", 1: \"machine\"}\n",
    "    label2id = {\"human\": 0, \"machine\": 1}\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "        )\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    def preprocess_function(examples, **fn_kwargs):\n",
    "        return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n",
    "\n",
    "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        # compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(tokenized_test_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    probs = softmax(predictions.predictions, axis=-1)\n",
    "    label_specific_probs = probs[:, 1]  # This extracts the probability for label 1\n",
    "    \n",
    "    return list(preds),list(label_specific_probs)\n",
    "\n",
    "def getPredictionMultidomain(model_path,num_extra_dims,test_data):\n",
    "    config = RobertaConfig.from_pretrained(model_path)\n",
    "    model = CustomSequenceClassification(config, num_extra_dims)\n",
    "    model.load_state_dict(torch.load(model_path+'/pytorch_model.bin'))\n",
    "    trainer = Trainer(model=model)\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(test_data)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    probs = softmax(predictions.predictions, axis=-1)\n",
    "    label_specific_probs = probs[:, 1]  # This extracts the probability for label 1\n",
    "    \n",
    "    return list(preds),list(label_specific_probs)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL1}')\n",
    "labels1,scores1=getPrediction(MODEL_PATH1)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL2}')\n",
    "labels2,scores2=getPrediction(MODEL_PATH2)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL3}')\n",
    "labels3,scores3=getPrediction(MODEL_PATH3)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL4}')\n",
    "labels4,scores4=getPrediction(MODEL_PATH4)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL5}')\n",
    "labels5,scores5=getPrediction(MODEL_PATH5)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL6}')\n",
    "labels6,scores6=getPrediction(MODEL_PATH6)\n",
    "\n",
    "df_multidomain=pd.read_csv('datasets/features_df_test.csv')\n",
    "df_multidomain_extended=pd.read_csv('datasets/features_df_test_extended.csv')\n",
    "\n",
    "df_multidomain_extraData=df_multidomain.drop(['label'],axis=1)\n",
    "df_multidomain_extraData=df_multidomain_extraData.drop(['text'],axis=1)\n",
    "\n",
    "df_multidomain_extended_extraData=df_multidomain_extended.drop(['label'],axis=1)\n",
    "df_multidomain_extended_extraData=df_multidomain_extended_extraData.drop(['text'],axis=1)\n",
    "\n",
    "ds_test = Dataset.from_dict({\n",
    "        \"text\": df_multidomain['text'].tolist(), \n",
    "        \"extra_data\": df_multidomain_extraData.values.tolist(),\n",
    "        \"labels\": df_multidomain['label'].tolist()\n",
    "    })\n",
    "\n",
    "ds_test_extended = Dataset.from_dict({\n",
    "        \"text\": df_multidomain_extended['text'].tolist(), \n",
    "        \"extra_data\": df_multidomain_extended_extraData.values.tolist(),\n",
    "        \"labels\": df_multidomain_extended['label'].tolist()\n",
    "    })\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "tokenized_ds_test = ds_test.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True))\n",
    "tokenized_ds_test = tokenized_ds_test.map(lambda x: {'extra_data': x['extra_data']})\n",
    "tokenized_ds_test_extended = ds_test_extended.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True))\n",
    "tokenized_ds_test_extended = tokenized_ds_test_extended.map(lambda x: {'extra_data': x['extra_data']})\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8}')\n",
    "labels8,scores8=getPredictionMultidomain(MODEL_PATH8,5,tokenized_ds_test)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL9}')\n",
    "labels9,scores9=getPredictionMultidomain(MODEL_PATH9,9,tokenized_ds_test_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "{'f1': 0.7835800547378446, 'confusion_matrix': [[1935, 565], [517, 1983]], 'accuracy': 0.7836, 'precision': 0.7782574568288854, 'recall': 0.7932, 'auc': 0.7836000000000001}\n",
      "\n",
      "Hello-SimpleAI/chatgpt-detector-roberta\n",
      "{'f1': 0.7197234156820624, 'confusion_matrix': [[2372, 128], [1208, 1292]], 'accuracy': 0.7328, 'precision': 0.9098591549295775, 'recall': 0.5168, 'auc': 0.7328}\n",
      "\n",
      "roberta-base-openai-detector\n",
      "{'f1': 0.8644663083985576, 'confusion_matrix': [[2371, 129], [544, 1956]], 'accuracy': 0.8654, 'precision': 0.9381294964028777, 'recall': 0.7824, 'auc': 0.8654}\n",
      "\n",
      "roberta-base\n",
      "{'f1': 0.8417475804685544, 'confusion_matrix': [[2059, 441], [350, 2150]], 'accuracy': 0.8418, 'precision': 0.8297954457738325, 'recall': 0.86, 'auc': 0.8418}\n",
      "\n",
      "distilbert-base-uncased\n",
      "{'f1': 0.7442622033685506, 'confusion_matrix': [[2189, 311], [947, 1553]], 'accuracy': 0.7484, 'precision': 0.8331545064377682, 'recall': 0.6212, 'auc': 0.7484}\n",
      "\n",
      "google/electra-base-discriminator\n",
      "{'f1': 0.777975985882633, 'confusion_matrix': [[1919, 581], [529, 1971]], 'accuracy': 0.778, 'precision': 0.7723354231974922, 'recall': 0.7884, 'auc': 0.778}\n",
      "\n",
      "Features Model\n",
      "{'f1': 0.6909230472951077, 'confusion_matrix': [[1846, 654], [888, 1612]], 'accuracy': 0.6916, 'precision': 0.7113857016769638, 'recall': 0.6448, 'auc': 0.6916}\n",
      "\n",
      "multidomain-roberta-base\n",
      "{'f1': 0.8279256820457738, 'confusion_matrix': [[2228, 272], [585, 1915]], 'accuracy': 0.8286, 'precision': 0.8756287151348879, 'recall': 0.766, 'auc': 0.8286}\n",
      "\n",
      "multidomain-extended-roberta-base\n",
      "{'f1': 0.848560256153625, 'confusion_matrix': [[2162, 338], [419, 2081]], 'accuracy': 0.8486, 'precision': 0.8602728400165358, 'recall': 0.8324, 'auc': 0.8486}\n"
     ]
    }
   ],
   "source": [
    "def getMetrics(predicted_labels, true_labels):\n",
    "    # Ensure the labels are numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')[2]\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "    auc = roc_auc_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "feature_df=pd.read_csv('datasets/features_df_test.csv')\n",
    "best_features=['word_count', 'avg_sentence_length', 'avg_word_length', 'gunning_fog_index', 'grammatical_errors']\n",
    "feature_df=feature_df[best_features]\n",
    "\n",
    "with open('SavedModels_A/optimized-rf-features-20k.pkl', 'rb') as file:\n",
    "    randomForest = pickle.load(file)\n",
    "MODEL7='Features Model'\n",
    "labels7=randomForest.predict(feature_df)\n",
    "probabilities = randomForest.predict_proba(feature_df)\n",
    "scores7 = probabilities.max(axis=1)\n",
    "\n",
    "print(MODEL1)\n",
    "print(getMetrics(labels1,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL2)\n",
    "print(getMetrics(labels2,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL3)\n",
    "print(getMetrics(labels3,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL4)\n",
    "print(getMetrics(labels4,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL5)\n",
    "print(getMetrics(labels5,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL6)\n",
    "print(getMetrics(labels6,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL7)\n",
    "print(getMetrics(labels7,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL8)\n",
    "print(getMetrics(labels8,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL9)\n",
    "print(getMetrics(labels9,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Labels_bert-base-uncased                        5000 non-null   int64  \n",
      " 1   Scores_bert-base-uncased                        5000 non-null   float32\n",
      " 2   Labels_Hello-SimpleAI/chatgpt-detector-roberta  5000 non-null   int64  \n",
      " 3   Scores_Hello-SimpleAI/chatgpt-detector-roberta  5000 non-null   float32\n",
      " 4   Labels_roberta-base-openai-detector             5000 non-null   int64  \n",
      " 5   Scores_roberta-base-openai-detector             5000 non-null   float32\n",
      " 6   Labels_roberta-base                             5000 non-null   int64  \n",
      " 7   Scores_roberta-base                             5000 non-null   float32\n",
      " 8   Labels_distilbert-base-uncased                  5000 non-null   int64  \n",
      " 9   Scores_distilbert-base-uncased                  5000 non-null   float32\n",
      " 10  Labels_google/electra-base-discriminator        5000 non-null   int64  \n",
      " 11  Scores_google/electra-base-discriminator        5000 non-null   float32\n",
      " 12  Labels_Features Model                           5000 non-null   int64  \n",
      " 13  Scores_Features Model                           5000 non-null   float64\n",
      " 14  Labels_multidomain-roberta-base                 5000 non-null   int64  \n",
      " 15  Scores_multidomain-roberta-base                 5000 non-null   float32\n",
      " 16  Labels_multidomain-extended-roberta-base        5000 non-null   int64  \n",
      " 17  Scores_multidomain-extended-roberta-base        5000 non-null   float32\n",
      "dtypes: float32(8), float64(1), int64(9)\n",
      "memory usage: 547.0 KB\n",
      "Majority Voting: 0.866096607048386\n",
      "Soft Voting: 0.7194420736479322\n",
      "Rank Voting: 0.5315710061736914\n",
      "Borda Count: 0.7890459123442917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = [MODEL1, MODEL2, MODEL3, MODEL4, MODEL5, MODEL6, MODEL7, MODEL8, MODEL9]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    f'Labels_{MODEL1}': labels1,\n",
    "    f'Scores_{MODEL1}': scores1,\n",
    "    f'Labels_{MODEL2}': labels2,\n",
    "    f'Scores_{MODEL2}': scores2,\n",
    "    f'Labels_{MODEL3}': labels3,\n",
    "    f'Scores_{MODEL3}': scores3,\n",
    "    f'Labels_{MODEL4}': labels4,\n",
    "    f'Scores_{MODEL4}': scores4,\n",
    "    f'Labels_{MODEL5}': labels5,\n",
    "    f'Scores_{MODEL5}': scores5,\n",
    "    f'Labels_{MODEL6}': labels6,\n",
    "    f'Scores_{MODEL6}': scores6,\n",
    "    f'Labels_{MODEL7}': labels7,\n",
    "    f'Scores_{MODEL7}': scores7,\n",
    "    f'Labels_{MODEL8}': labels8,\n",
    "    f'Scores_{MODEL8}': scores8,\n",
    "    f'Labels_{MODEL9}': labels9,\n",
    "    f'Scores_{MODEL9}': scores9,\n",
    "})\n",
    "\n",
    "labels = test_df['label'].tolist()\n",
    "\n",
    "df.info()\n",
    "\n",
    "def ensemble_methods(df, models):\n",
    "    \n",
    "    majority_labels = []\n",
    "    score_based_labels = []\n",
    "    rank_voting_labels = []\n",
    "    borda_count_labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        label_counts = {0: 0, 1: 0}\n",
    "        score_sums = {0: 0.0, 1: 0.0}\n",
    "        weighted_scores = {0: 0.0, 1: 0.0}\n",
    "\n",
    "        for i, model in enumerate(models):\n",
    "            label = row[f'Labels_{model}']\n",
    "            score = row[f'Scores_{model}']\n",
    "            label_counts[label] += 1\n",
    "            score_sums[label] += score\n",
    "\n",
    "        # Majority Voting\n",
    "        majority_label = 0 if label_counts[0] > label_counts[1] else 1\n",
    "        majority_labels.append(majority_label)\n",
    "\n",
    "        # Soft Voting\n",
    "        avg_score_0 = score_sums[0] / (label_counts[0] if label_counts[0] else 1)\n",
    "        avg_score_1 = score_sums[1] / (label_counts[1] if label_counts[1] else 1)\n",
    "        score_based_label = 0 if avg_score_0 > avg_score_1 else 1\n",
    "        score_based_labels.append(score_based_label)\n",
    "        \n",
    "        # Rank Voting\n",
    "        ranks = [row[f'Scores_{model}'] for model in models]\n",
    "        ranked_labels = [label for _, label in sorted(zip(ranks, [row[f'Labels_{model}'] for model in models]))]\n",
    "        rank_voting_labels.append(ranked_labels[0])  # The label with the lowest rank\n",
    "\n",
    "        # Borda Count\n",
    "        borda_scores = {0: 0, 1: 0}\n",
    "        for rank, label in enumerate(ranked_labels):\n",
    "            borda_scores[label] += (len(models) - rank)\n",
    "        borda_count_labels.append(max(borda_scores, key=borda_scores.get))\n",
    "        \n",
    "    return {\n",
    "        'Majority Voting':majority_labels,\n",
    "        'Soft Voting':score_based_labels,\n",
    "        'Rank Voting':rank_voting_labels,\n",
    "        'Borda Count':borda_count_labels,\n",
    "    }\n",
    "\n",
    "ensemble_results = ensemble_methods(df, models)\n",
    "\n",
    "for voting_method, details in ensemble_results.items():\n",
    "    print(f'''{voting_method}: {getMetrics(details,labels)['f1']}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Combinations: 100%|██████████| 9/9 [01:39<00:00, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy Score: 0.8868\n",
      "Best Model Combination: ('roberta-base-openai-detector', 'roberta-base', 'google/electra-base-discriminator', 'Features Model', 'multidomain-roberta-base', 'multidomain-extended-roberta-base')\n",
      "Best Voting Method: Majority Voting\n",
      "Best Metrics: {'f1': 0.8867599764460752, 'confusion_matrix': [[2170, 330], [236, 2264]], 'accuracy': 0.8868, 'precision': 0.8727833461835004, 'recall': 0.9056, 'auc': 0.8867999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Assuming all_models is a list of your model names\n",
    "all_models = [MODEL1, MODEL2, MODEL3, MODEL4, MODEL5, MODEL6, MODEL7, MODEL8, MODEL9]\n",
    "\n",
    "# This will store the best F1 score, the corresponding model combination, and the voting method\n",
    "best_f1_score = 0\n",
    "best_model_combination = None\n",
    "best_voting_method = None\n",
    "\n",
    "# Define the voting methods you want to evaluate\n",
    "voting_methods = ['Majority Voting', 'Soft Voting', 'Rank Voting', 'Borda Count']\n",
    "\n",
    "# Try all possible combinations of the models\n",
    "# for r in tqdm(range(1, len(all_models) + 1), desc='Model Combinations'):\n",
    "#     for model_combination in itertools.combinations(all_models, r):\n",
    "#         # Generate the predictions using the ensemble of the current combination of models\n",
    "#         ensemble_results = ensemble_methods(df, model_combination)\n",
    "        \n",
    "#         # Evaluate each voting method\n",
    "#         for method in voting_methods:\n",
    "#             f1_score = getMetrics(ensemble_results[method], labels)['f1']\n",
    "            \n",
    "#             # Update the best combination if the current one is better\n",
    "#             if f1_score > best_f1_score:\n",
    "#                 best_f1_score = f1_score\n",
    "#                 best_model_combination = model_combination\n",
    "#                 best_voting_method = method\n",
    "\n",
    "# # Print the best combination, its score, and the voting method\n",
    "# print(f\"Best F1 Score: {best_f1_score}\")\n",
    "# print(f\"Best Model Combination: {best_model_combination}\")\n",
    "# print(f\"Best Voting Method: {best_voting_method}\")\n",
    "\n",
    "for r in tqdm(range(1, len(all_models) + 1), desc='Model Combinations'):\n",
    "    for model_combination in itertools.combinations(all_models, r):\n",
    "        # Generate the predictions using the ensemble of the current combination of models\n",
    "        ensemble_results = ensemble_methods(df, model_combination)\n",
    "        \n",
    "        # Evaluate each voting method\n",
    "        for method in voting_methods:\n",
    "            metrics=getMetrics(ensemble_results[method], labels)\n",
    "            f1_score=metrics['accuracy']\n",
    "            \n",
    "            # Update the best combination if the current one is better\n",
    "            if f1_score > best_f1_score:\n",
    "                best_f1_score = f1_score\n",
    "                best_model_combination = model_combination\n",
    "                best_voting_method = method\n",
    "                best_metrics=metrics\n",
    "\n",
    "# Print the best combination, its score, and the voting method\n",
    "print(f\"Best Accuracy Score: {best_f1_score}\")\n",
    "print(f\"Best Model Combination: {best_model_combination}\")\n",
    "print(f\"Best Voting Method: {best_voting_method}\")\n",
    "print(f\"Best Metrics: {best_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting: 0.8868\n",
      "Soft Voting: 0.758\n",
      "Rank Voting: 0.6654\n",
      "Borda Count: 0.8198\n"
     ]
    }
   ],
   "source": [
    "models = [MODEL3, MODEL4, MODEL6, MODEL7, MODEL8, MODEL9]\n",
    "\n",
    "df_reduced = pd.DataFrame({\n",
    "    f'Labels_{MODEL3}': labels3,\n",
    "    f'Scores_{MODEL3}': scores3,\n",
    "    f'Labels_{MODEL4}': labels4,\n",
    "    f'Scores_{MODEL4}': scores4,\n",
    "    f'Labels_{MODEL6}': labels6,\n",
    "    f'Scores_{MODEL6}': scores6,\n",
    "    f'Labels_{MODEL7}': labels7,\n",
    "    f'Scores_{MODEL7}': scores7,\n",
    "    f'Labels_{MODEL8}': labels8,\n",
    "    f'Scores_{MODEL8}': scores8,\n",
    "    f'Labels_{MODEL9}': labels9,\n",
    "    f'Scores_{MODEL9}': scores9,\n",
    "})\n",
    "\n",
    "ensemble_results = ensemble_methods(df, models)\n",
    "\n",
    "for voting_method, details in ensemble_results.items():\n",
    "    print(f'''{voting_method}: {getMetrics(details,labels)['accuracy']}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "4995    4995\n",
       "4996    4996\n",
       "4997    4997\n",
       "4998    4998\n",
       "4999    4999\n",
       "Name: id, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_labels=ensemble_results['Majority Voting']\n",
    "df = pd.read_json('datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result_labels = [int(num) for num in result_labels]\n",
    "\n",
    "# Display the distribution of integer values\n",
    "plt.hist(result_labels, bins=range(min(result_labels), max(result_labels) + 2), align='left')\n",
    "plt.xlabel('Integer Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Integer Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'id': df['id'],\n",
    "    'label': result_labels\n",
    "})\n",
    "\n",
    "# Exporting to a jsonl file\n",
    "new_df.to_json('datasets/subtask_a_monolingual.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
