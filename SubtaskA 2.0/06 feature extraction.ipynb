{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback,AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textstat.textstat import textstatistics\n",
    "import pandas as pd\n",
    "import language_tool_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    5309\n",
      "1    4691\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_json('datasets/subtaskA_train_monolingual.jsonl', lines=True)\n",
    "df=df.sample(10000)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ghiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ghiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize the grammar checker\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def extract_text_features(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(sentences)\n",
    "\n",
    "    # Lexical diversity\n",
    "    unique_words = set(words)\n",
    "    lexical_diversity = len(unique_words) / word_count\n",
    "\n",
    "    # Average sentence length\n",
    "    avg_sentence_length = word_count / sentence_count\n",
    "\n",
    "    # Average word length\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count\n",
    "\n",
    "    # Lexical density\n",
    "    tags = nltk.pos_tag(words)\n",
    "    content_words = [word for word, tag in tags if tag.startswith(('N', 'V', 'J', 'R'))]\n",
    "    lexical_density = len(content_words) / word_count\n",
    "\n",
    "    # Readability scores\n",
    "    flesch_reading_ease = textstatistics().flesch_reading_ease(text)\n",
    "    fog_index = textstatistics().gunning_fog(text)\n",
    "\n",
    "    # Grammatical errors\n",
    "    matches = tool.check(text)\n",
    "    grammatical_errors = len(matches)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    return pd.Series({\n",
    "        'word_count': word_count,\n",
    "        'sentence_count': sentence_count,\n",
    "        'lexical_diversity': lexical_diversity,\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'lexical_density': lexical_density,\n",
    "        'flesch_reading_ease': flesch_reading_ease,\n",
    "        'gunning_fog_index': fog_index,\n",
    "        'grammatical_errors': grammatical_errors\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [24:40<00:00,  6.76it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammatical_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>112437</th>\n",
       "      <td>285.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>25.909091</td>\n",
       "      <td>5.164912</td>\n",
       "      <td>0.617544</td>\n",
       "      <td>35.88</td>\n",
       "      <td>12.34</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33312</th>\n",
       "      <td>298.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.503356</td>\n",
       "      <td>27.090909</td>\n",
       "      <td>4.986577</td>\n",
       "      <td>0.550336</td>\n",
       "      <td>37.84</td>\n",
       "      <td>15.93</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43548</th>\n",
       "      <td>238.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.466387</td>\n",
       "      <td>18.307692</td>\n",
       "      <td>5.172269</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>37.50</td>\n",
       "      <td>12.41</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90838</th>\n",
       "      <td>229.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.576419</td>\n",
       "      <td>8.807692</td>\n",
       "      <td>3.864629</td>\n",
       "      <td>0.510917</td>\n",
       "      <td>71.31</td>\n",
       "      <td>6.41</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39065</th>\n",
       "      <td>273.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>30.333333</td>\n",
       "      <td>4.761905</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>36.42</td>\n",
       "      <td>15.56</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58200</th>\n",
       "      <td>653.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.437979</td>\n",
       "      <td>31.095238</td>\n",
       "      <td>4.304747</td>\n",
       "      <td>0.493109</td>\n",
       "      <td>54.66</td>\n",
       "      <td>13.24</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60295</th>\n",
       "      <td>1025.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.318049</td>\n",
       "      <td>18.636364</td>\n",
       "      <td>3.715122</td>\n",
       "      <td>0.480976</td>\n",
       "      <td>88.26</td>\n",
       "      <td>7.54</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110977</th>\n",
       "      <td>321.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.526480</td>\n",
       "      <td>45.857143</td>\n",
       "      <td>4.750779</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>21.50</td>\n",
       "      <td>22.51</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25456</th>\n",
       "      <td>190.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.115789</td>\n",
       "      <td>0.515789</td>\n",
       "      <td>27.08</td>\n",
       "      <td>18.45</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58643</th>\n",
       "      <td>1199.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.359466</td>\n",
       "      <td>19.031746</td>\n",
       "      <td>3.955796</td>\n",
       "      <td>0.483736</td>\n",
       "      <td>80.82</td>\n",
       "      <td>8.15</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        word_count  sentence_count  lexical_diversity  avg_sentence_length  \\\n",
       "112437       285.0            11.0           0.543860            25.909091   \n",
       "33312        298.0            11.0           0.503356            27.090909   \n",
       "43548        238.0            13.0           0.466387            18.307692   \n",
       "90838        229.0            26.0           0.576419             8.807692   \n",
       "39065        273.0             9.0           0.527473            30.333333   \n",
       "...            ...             ...                ...                  ...   \n",
       "58200        653.0            21.0           0.437979            31.095238   \n",
       "60295       1025.0            55.0           0.318049            18.636364   \n",
       "110977       321.0             7.0           0.526480            45.857143   \n",
       "25456        190.0             5.0           0.447368            38.000000   \n",
       "58643       1199.0            63.0           0.359466            19.031746   \n",
       "\n",
       "        avg_word_length  lexical_density  flesch_reading_ease  \\\n",
       "112437         5.164912         0.617544                35.88   \n",
       "33312          4.986577         0.550336                37.84   \n",
       "43548          5.172269         0.567227                37.50   \n",
       "90838          3.864629         0.510917                71.31   \n",
       "39065          4.761905         0.538462                36.42   \n",
       "...                 ...              ...                  ...   \n",
       "58200          4.304747         0.493109                54.66   \n",
       "60295          3.715122         0.480976                88.26   \n",
       "110977         4.750779         0.504673                21.50   \n",
       "25456          5.115789         0.515789                27.08   \n",
       "58643          3.955796         0.483736                80.82   \n",
       "\n",
       "        gunning_fog_index  grammatical_errors  \n",
       "112437              12.34                 6.0  \n",
       "33312               15.93                 2.0  \n",
       "43548               12.41                 1.0  \n",
       "90838                6.41                 5.0  \n",
       "39065               15.56                15.0  \n",
       "...                   ...                 ...  \n",
       "58200               13.24                20.0  \n",
       "60295                7.54                14.0  \n",
       "110977              22.51                 7.0  \n",
       "25456               18.45                 2.0  \n",
       "58643                8.15                14.0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "features_df = df['text'].progress_apply(extract_text_features)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature lexical_diversity (0.1959888298175121)\n",
      "2. feature grammatical_errors (0.18588589402068853)\n",
      "3. feature word_count (0.14293442095584902)\n",
      "4. feature avg_word_length (0.10139951225306561)\n",
      "5. feature avg_sentence_length (0.09058214449399676)\n",
      "6. feature flesch_reading_ease (0.0723916598476359)\n",
      "7. feature sentence_count (0.07148867120696319)\n",
      "8. feature lexical_density (0.07134239322180339)\n",
      "9. feature gunning_fog_index (0.06798647418248556)\n",
      "f1: 0.8415728446802802\n",
      "confusion_matrix: [[919, 145], [170, 766]]\n",
      "accuracy: 0.8425\n",
      "precision: 0.8408342480790341\n",
      "recall: 0.8183760683760684\n",
      "auc: 0.8410489364436733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare your data\n",
    "X = features_df  # Your extracted features\n",
    "y = df['label']  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature rankings\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(f\"{f + 1}. feature {feature_names[indices[f]]} ({importances[indices[f]]})\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def getMetrics(predicted_labels, true_labels):\n",
    "    # Ensure the labels are numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')[2]\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "    auc = roc_auc_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        'f1': f1,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Assuming clf is your trained model and X_test, y_test are your test features and labels\n",
    "predicted_labels = clf.predict(X_test)\n",
    "metrics = getMetrics(predicted_labels, y_test)\n",
    "\n",
    "# Print the metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best Parameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 7, 'n_estimators': 350}\n",
      "f1: 0.8361024972750783\n",
      "confusion_matrix: [[911, 153], [173, 763]]\n",
      "accuracy: 0.837\n",
      "precision: 0.8329694323144105\n",
      "recall: 0.8151709401709402\n",
      "auc: 0.8356869738448686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [250,300,350],  # Number of trees in the random forest\n",
    "    'max_features': ['sqrt'],  # Number of features to consider at every split\n",
    "    'max_depth': [None],  # Maximum number of levels in tree\n",
    "    'min_samples_split': [3,5,7,9],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1],  # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True]  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "# Now you can use best_grid to make predictions and evaluate it\n",
    "predicted_labels = best_grid.predict(X_test)\n",
    "metrics = getMetrics(predicted_labels, y_test)\n",
    "\n",
    "# Print the metrics\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [09:35<00:00,  8.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.47029538665781623,\n",
       " 'confusion_matrix': [[2078, 422], [1972, 528]],\n",
       " 'accuracy': 0.5212,\n",
       " 'precision': 0.5557894736842105,\n",
       " 'recall': 0.2112,\n",
       " 'auc': 0.5211999999999999}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df= pd.read_json('datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "\n",
    "test_features_df = test_df['text'].progress_apply(extract_text_features)\n",
    "print(test_features_df.shape)\n",
    "\n",
    "test_X = test_features_df  # Your extracted features\n",
    "test_y = test_df['label']  # Labels\n",
    "\n",
    "predicted_labels = best_grid.predict(test_X)\n",
    "getMetrics(predicted_labels, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ola\n"
     ]
    }
   ],
   "source": [
    "print('ola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('filename.pkl', 'wb') as file:\n",
    "    pickle.dump(best_grid, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
