{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import json\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import pandas as pd,os\n",
    "import torch\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, **fn_kwargs):\n",
    "    return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n",
    "def get_data(train_path, test_path, random_seed):\n",
    "    \"\"\"\n",
    "    function to read dataframe with columns\n",
    "    \"\"\"\n",
    "\n",
    "    train_df = pd.read_json(train_path, lines=True)\n",
    "    test_df = pd.read_json(test_path, lines=True)\n",
    "    \n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=random_seed)\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "def fine_tune(train_df, valid_df, checkpoints_path, id2label, label2id, model):\n",
    "\n",
    "    # pandas dataframe to huggingface Dataset\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    valid_dataset = Dataset.from_pandas(valid_df)\n",
    "    \n",
    "    # get tokenizer and model from huggingface\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)     # put your model here\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       model, num_labels=len(label2id), id2label=id2label, label2id=label2id    # put your model here\n",
    "    )\n",
    "    \n",
    "    # tokenize data for train/valid\n",
    "    tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
    "    tokenized_valid_dataset = valid_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "    \n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "    # create Trainer \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=checkpoints_path,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train_dataset,\n",
    "        eval_dataset=tokenized_valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # save best model\n",
    "    best_model_path = checkpoints_path+'/best/'\n",
    "    \n",
    "    if not os.path.exists(best_model_path):\n",
    "        os.makedirs(best_model_path)\n",
    "    \n",
    "\n",
    "    trainer.save_model(best_model_path)\n",
    "def test(test_df, model_path, id2label, label2id):\n",
    "    \n",
    "    # load tokenizer from saved model \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # load best model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "       model_path, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "    )\n",
    "            \n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(tokenized_test_dataset)\n",
    "    prob_pred = softmax(predictions.predictions, axis=-1)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    metric = evaluate.load(\"bstrai/classification_report\")\n",
    "    results = metric.compute(predictions=preds, references=predictions.label_ids)\n",
    "    \n",
    "    # return dictionary of classification report\n",
    "    return results, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 80/80 [00:00<00:00, 1450.71 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 968.67 examples/s]\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 33%|███▎      | 5/15 [00:01<00:02,  4.10it/s]Trainer is attempting to log a value of \"[[8, 3], [5, 4]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                              \n",
      " 33%|███▎      | 5/15 [00:01<00:02,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7008172869682312, 'eval_accuracy': 0.6, 'eval_f1': 0.5, 'eval_auc': 0.5858585858585859, 'eval_precision': 0.5714285714285714, 'eval_recall': 0.4444444444444444, 'eval_confusion_matrix': [[8, 3], [5, 4]], 'eval_runtime': 0.1073, 'eval_samples_per_second': 186.375, 'eval_steps_per_second': 18.637, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:03<00:01,  3.22it/s]Trainer is attempting to log a value of \"[[9, 2], [8, 1]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      " 67%|██████▋   | 10/15 [00:03<00:01,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6860108375549316, 'eval_accuracy': 0.5, 'eval_f1': 0.16666666666666666, 'eval_auc': 0.46464646464646464, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.1111111111111111, 'eval_confusion_matrix': [[9, 2], [8, 1]], 'eval_runtime': 0.1061, 'eval_samples_per_second': 188.581, 'eval_steps_per_second': 18.858, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:05<00:00,  3.13it/s]Trainer is attempting to log a value of \"[[9, 2], [8, 1]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      "100%|██████████| 15/15 [00:05<00:00,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6884660124778748, 'eval_accuracy': 0.5, 'eval_f1': 0.16666666666666666, 'eval_auc': 0.46464646464646464, 'eval_precision': 0.3333333333333333, 'eval_recall': 0.1111111111111111, 'eval_confusion_matrix': [[9, 2], [8, 1]], 'eval_runtime': 0.1065, 'eval_samples_per_second': 187.872, 'eval_steps_per_second': 18.787, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 7.1917, 'train_samples_per_second': 33.372, 'train_steps_per_second': 2.086, 'train_loss': 0.6712141036987305, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 3228.84 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 500/500 [00:20<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** 100 - 0.3344434824928323 ******\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 160/160 [00:00<00:00, 1397.20 examples/s]\n",
      "Map: 100%|██████████| 40/40 [00:00<00:00, 1764.78 examples/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 33%|███▎      | 10/30 [00:02<00:04,  4.38it/s]Trainer is attempting to log a value of \"[[4, 14], [3, 19]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      " 33%|███▎      | 10/30 [00:02<00:04,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6603240370750427, 'eval_accuracy': 0.575, 'eval_f1': 0.6909090909090909, 'eval_auc': 0.5429292929292929, 'eval_precision': 0.5757575757575758, 'eval_recall': 0.8636363636363636, 'eval_confusion_matrix': [[4, 14], [3, 19]], 'eval_runtime': 0.2062, 'eval_samples_per_second': 194.012, 'eval_steps_per_second': 14.551, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:06<00:02,  4.15it/s]Trainer is attempting to log a value of \"[[2, 16], [2, 20]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      " 67%|██████▋   | 20/30 [00:06<00:02,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6857345700263977, 'eval_accuracy': 0.55, 'eval_f1': 0.6896551724137931, 'eval_auc': 0.51010101010101, 'eval_precision': 0.5555555555555556, 'eval_recall': 0.9090909090909091, 'eval_confusion_matrix': [[2, 16], [2, 20]], 'eval_runtime': 0.206, 'eval_samples_per_second': 194.15, 'eval_steps_per_second': 14.561, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:10<00:00,  4.09it/s]Trainer is attempting to log a value of \"[[4, 14], [2, 20]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      "100%|██████████| 30/30 [00:10<00:00,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6565167307853699, 'eval_accuracy': 0.6, 'eval_f1': 0.7142857142857143, 'eval_auc': 0.5656565656565656, 'eval_precision': 0.5882352941176471, 'eval_recall': 0.9090909090909091, 'eval_confusion_matrix': [[4, 14], [2, 20]], 'eval_runtime': 0.2069, 'eval_samples_per_second': 193.308, 'eval_steps_per_second': 14.498, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11.8755, 'train_samples_per_second': 40.419, 'train_steps_per_second': 2.526, 'train_loss': 0.633319600423177, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 3084.59 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 500/500 [00:20<00:00, 24.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** 200 - 0.363069247743454 ******\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 240/240 [00:00<00:00, 1613.48 examples/s]\n",
      "Map: 100%|██████████| 60/60 [00:00<00:00, 1244.35 examples/s]\n",
      "  0%|          | 0/45 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 33%|███▎      | 15/45 [00:03<00:06,  4.46it/s]Trainer is attempting to log a value of \"[[17, 12], [6, 25]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "\n",
      " 33%|███▎      | 15/45 [00:03<00:06,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6516216397285461, 'eval_accuracy': 0.7, 'eval_f1': 0.7352941176470588, 'eval_auc': 0.696329254727475, 'eval_precision': 0.6756756756756757, 'eval_recall': 0.8064516129032258, 'eval_confusion_matrix': [[17, 12], [6, 25]], 'eval_runtime': 0.3199, 'eval_samples_per_second': 187.55, 'eval_steps_per_second': 12.503, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 30/45 [00:08<00:03,  4.40it/s]Trainer is attempting to log a value of \"[[23, 6], [13, 18]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "\n",
      " 67%|██████▋   | 30/45 [00:08<00:03,  4.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6173883080482483, 'eval_accuracy': 0.6833333333333333, 'eval_f1': 0.6545454545454547, 'eval_auc': 0.6868743047830923, 'eval_precision': 0.75, 'eval_recall': 0.5806451612903226, 'eval_confusion_matrix': [[23, 6], [13, 18]], 'eval_runtime': 0.3061, 'eval_samples_per_second': 196.044, 'eval_steps_per_second': 13.07, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:12<00:00,  4.41it/s]Trainer is attempting to log a value of \"[[19, 10], [8, 23]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "\n",
      "100%|██████████| 45/45 [00:13<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.611975908279419, 'eval_accuracy': 0.7, 'eval_f1': 0.71875, 'eval_auc': 0.6985539488320356, 'eval_precision': 0.696969696969697, 'eval_recall': 0.7419354838709677, 'eval_confusion_matrix': [[19, 10], [8, 23]], 'eval_runtime': 0.3057, 'eval_samples_per_second': 196.256, 'eval_steps_per_second': 13.084, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:14<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.549, 'train_samples_per_second': 49.488, 'train_steps_per_second': 3.093, 'train_loss': 0.6333093855116102, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 2922.83 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 500/500 [00:20<00:00, 24.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** 300 - 0.34927575441021086 ******\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 320/320 [00:00<00:00, 1664.51 examples/s]\n",
      "Map: 100%|██████████| 80/80 [00:00<00:00, 1123.16 examples/s]\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 33%|███▎      | 20/60 [00:04<00:08,  4.48it/s]Trainer is attempting to log a value of \"[[16, 22], [5, 37]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      " 33%|███▎      | 20/60 [00:05<00:08,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6400076150894165, 'eval_accuracy': 0.6625, 'eval_f1': 0.7326732673267327, 'eval_auc': 0.6510025062656641, 'eval_precision': 0.6271186440677966, 'eval_recall': 0.8809523809523809, 'eval_confusion_matrix': [[16, 22], [5, 37]], 'eval_runtime': 0.4107, 'eval_samples_per_second': 194.789, 'eval_steps_per_second': 12.174, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40/60 [00:10<00:04,  4.44it/s]Trainer is attempting to log a value of \"[[17, 21], [5, 37]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      " 67%|██████▋   | 40/60 [00:11<00:04,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6154470443725586, 'eval_accuracy': 0.675, 'eval_f1': 0.7400000000000001, 'eval_auc': 0.6641604010025062, 'eval_precision': 0.6379310344827587, 'eval_recall': 0.8809523809523809, 'eval_confusion_matrix': [[17, 21], [5, 37]], 'eval_runtime': 0.4163, 'eval_samples_per_second': 192.188, 'eval_steps_per_second': 12.012, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:16<00:00,  4.47it/s]Trainer is attempting to log a value of \"[[22, 16], [8, 34]]\" of type <class 'list'> for key \"eval/confusion_matrix\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                               \n",
      "100%|██████████| 60/60 [00:17<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5951750874519348, 'eval_accuracy': 0.7, 'eval_f1': 0.7391304347826089, 'eval_auc': 0.6942355889724311, 'eval_precision': 0.68, 'eval_recall': 0.8095238095238095, 'eval_confusion_matrix': [[22, 16], [8, 34]], 'eval_runtime': 0.4072, 'eval_samples_per_second': 196.463, 'eval_steps_per_second': 12.279, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:18<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 18.2993, 'train_samples_per_second': 52.461, 'train_steps_per_second': 3.279, 'train_loss': 0.6342798233032226, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4000/4000 [00:01<00:00, 2955.90 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 500/500 [00:20<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "****** 400 - 0.5170642928932201 ******\n",
      "\n",
      "\n",
      "100 - 0.3344434824928323\n",
      "200 - 0.363069247743454\n",
      "300 - 0.34927575441021086\n",
      "400 - 0.5170642928932201\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (4,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ghiki\\Documents\\GitHub\\Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection\\SubtaskA 2.0\\07 training sample optimization.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/07%20training%20sample%20optimization.ipynb#W2sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/07%20training%20sample%20optimization.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/07%20training%20sample%20optimization.ipynb#W2sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(SAMPLES_TO_TRAIN, f1_scores, marker\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mo\u001b[39;49m\u001b[39m'\u001b[39;49m, linestyle\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/07%20training%20sample%20optimization.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mNumber of Training Samples\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ghiki/Documents/GitHub/Multidomain--Multimodal-and-Multilingual-Machine-Generated-Text-Detection/SubtaskA%202.0/07%20training%20sample%20optimization.ipynb#W2sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mF1 Score (Macro Avg)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3570\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   3571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\n\u001b[0;32m   3572\u001b[0m     \u001b[39m*\u001b[39margs: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m ArrayLike \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   3577\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3578\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   3579\u001b[0m         \u001b[39m*\u001b[39;49margs,\n\u001b[0;32m   3580\u001b[0m         scalex\u001b[39m=\u001b[39;49mscalex,\n\u001b[0;32m   3581\u001b[0m         scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   3582\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}),\n\u001b[0;32m   3583\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   3584\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32mc:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (4,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_seed = 0\n",
    "\n",
    "model = 'bert-base-uncased'\n",
    "\n",
    "samples=[500,1000,2000,4000,6000,8000]\n",
    "f1_scores = []\n",
    "\n",
    "for SAMPLES_TO_TRAIN in samples:\n",
    "\n",
    "    df= pd.read_json('datasets/subtaskA_train_multilingual.jsonl', lines=True)\n",
    "\n",
    "    # df = df.rename(columns={'source': 'language'})\n",
    "    # non_language_sources = ['wikihow', 'wikipedia', 'reddit', 'arxiv', 'peerread']\n",
    "    # df['language'] = df['language'].replace(non_language_sources, 'english')\n",
    "    # rus = RandomUnderSampler(random_state=42)\n",
    "    # X_resampled, y_resampled = rus.fit_resample(df.drop('language', axis=1), df['language'])\n",
    "    # df = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "    df=df.sample(SAMPLES_TO_TRAIN)\n",
    "\n",
    "    df.to_json('reducedTrainDataFrame.jsonl', orient='records', lines=True)\n",
    "\n",
    "    train_path =  'reducedTrainDataFrame.jsonl'\n",
    "    test_path =  'datasets/subtaskA_dev_multilingual.jsonl'\n",
    "\n",
    "    subtask =  'A'\n",
    "    prediction_path = 'reducedPredictedDataFrame.jsonl'\n",
    "\n",
    "    if not os.path.exists(train_path):\n",
    "        logging.error(\"File doesnt exists: {}\".format(train_path))\n",
    "        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n",
    "\n",
    "    if not os.path.exists(test_path):\n",
    "        logging.error(\"File doesnt exists: {}\".format(train_path))\n",
    "        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n",
    "\n",
    "    if subtask == 'A':\n",
    "        id2label = {0: \"human\", 1: \"machine\"}\n",
    "        label2id = {\"human\": 0, \"machine\": 1}\n",
    "    elif subtask == 'B':\n",
    "        id2label = {0: 'human', 1: 'chatGPT', 2: 'cohere', 3: 'davinci', 4: 'bloomz', 5: 'dolly'}\n",
    "        label2id = {'human': 0, 'chatGPT': 1,'cohere': 2, 'davinci': 3, 'bloomz': 4, 'dolly': 5}\n",
    "    else:\n",
    "        logging.error(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n",
    "        raise ValueError(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n",
    "\n",
    "    set_seed(random_seed)\n",
    "\n",
    "    train_df, valid_df, test_df = get_data(train_path, test_path, random_seed)\n",
    "\n",
    "    fine_tune(train_df, valid_df, f\"testing_models/{model.split('/')[-1]}_{SAMPLES_TO_TRAIN}\", id2label, label2id, model)\n",
    "\n",
    "    results, predictions = test(test_df, f\"testing_models/{model.split('/')[-1]}_{SAMPLES_TO_TRAIN}/best/\", id2label, label2id)\n",
    "\n",
    "    f1_score=results['macro avg']['f1-score']\n",
    "\n",
    "    with open(f\"testing_models/{model.split('/')[-1]}_{SAMPLES_TO_TRAIN}/best/f1_score.json\", 'w') as file:\n",
    "        json.dump({'f1_score': f1_score}, file)\n",
    "    \n",
    "    f1_scores.append(f1_score)\n",
    "        \n",
    "    print(f'\\n\\n****** {SAMPLES_TO_TRAIN} - {f1_score} ******\\n\\n')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)\n",
    "\n",
    "for SAMPLES_TO_TRAIN,f1_score in zip(samples,f1_scores):\n",
    "    print(f'{SAMPLES_TO_TRAIN} - {f1_score}')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plotting the graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(samples, f1_scores, marker='o', linestyle='-')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('F1 Score (Macro Avg)')\n",
    "plt.title('F1 Score vs Number of Training Samples')\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"testing_models/{model.split('/')[-1]}_{SAMPLES_TO_TRAIN}_f1_scores.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
