{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Variables and parameters transfer learning'''\n",
    "\n",
    "MODEL1='bert-base-uncased'\n",
    "MODEL2='microsoft/deberta-large'\n",
    "MODEL3='roberta-base'\n",
    "MODEL4='roberta-large'\n",
    "MODEL5='Hello-SimpleAI/chatgpt-detector-roberta'\n",
    "MODEL6='roberta-base-openai-detector'\n",
    "\n",
    "MODEL_PATH1='SavedModels/bert-base-uncased5k'\n",
    "MODEL_PATH2='SavedModels/deberta-large5k'\n",
    "MODEL_PATH3='SavedModels/roberta-base5k'\n",
    "MODEL_PATH4='SavedModels/roberta-large5k'\n",
    "MODEL_PATH5='SavedModels/chatgpt-detector-roberta5k'\n",
    "MODEL_PATH6='SavedModels/roberta-base-openai-detector5k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''metrics'''\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load tokenizers and models'''\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(MODEL1)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH1)\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH2)\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(MODEL3)\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH3)\n",
    "\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(MODEL4)\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH4)\n",
    "\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(MODEL5)\n",
    "model5 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH5)\n",
    "\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(MODEL6)\n",
    "model6 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH6)\n",
    "\n",
    "pipe1 = pipeline(\"text-classification\", model=model1, tokenizer=tokenizer1, device=0)\n",
    "pipe2 = pipeline(\"text-classification\", model=model2, tokenizer=tokenizer2, device=0)\n",
    "pipe3 = pipeline(\"text-classification\", model=model3, tokenizer=tokenizer3, device=0)\n",
    "pipe4 = pipeline(\"text-classification\", model=model4, tokenizer=tokenizer4, device=0)\n",
    "pipe5 = pipeline(\"text-classification\", model=model5, tokenizer=tokenizer5, device=0)\n",
    "pipe6 = pipeline(\"text-classification\", model=model6, tokenizer=tokenizer6, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Custom model architectures'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "input_dim = 200\n",
    "\n",
    "# number of classes (unique of y)\n",
    "output_dim = 2\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear4 = nn.Linear(256, output_dim)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x1 = F.leaky_relu(self.linear1(input_ids))\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "        \n",
    "        x2 = F.leaky_relu(self.linear2(x1))\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "        \n",
    "        # Adding the first skip connection\n",
    "        x2 += x1\n",
    "        \n",
    "        x3 = F.leaky_relu(self.linear3(x2))\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.dropout3(x3)\n",
    "        \n",
    "        x4 = self.linear4(x3)\n",
    "        \n",
    "        outputs = (x4,)\n",
    "        if labels is not None:\n",
    "            loss = self.loss(x4, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "            \n",
    "        return (outputs if len(outputs) > 1 else outputs[0])\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=100, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=150, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(150)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(150 * 200, 256)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Flatten the output for the dense layer\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(x, labels)\n",
    "            return loss, x\n",
    "        \n",
    "        return x\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_dim, 512, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(512, 512, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(512)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(512, output_dim)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        # print(f\"Input shape: {input_ids.shape}\")\n",
    "        \n",
    "        x, _ = self.lstm1(input_ids)\n",
    "        # print(f\"After LSTM1: {x.shape}\")\n",
    "\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # print(f\"Before LSTM2: {x.shape}\")\n",
    "        \n",
    "        x, _ = self.lstm2(x)\n",
    "        # print(f\"After LSTM2: {x.shape}\")\n",
    "\n",
    "        x = self.ln2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        # print(f\"Output shape: {x.shape}\")\n",
    "        \n",
    "        outputs = (x,)\n",
    "        if labels is not None:\n",
    "            loss = self.loss(x, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "            \n",
    "        return (outputs if len(outputs) > 1 else outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Custom model preparation'''\n",
    "\n",
    "CUSTOM_MODEL_NAME1='dense'\n",
    "CUSTOM_MODEL_NAME2='cnn'\n",
    "CUSTOM_MODEL_NAME3='lstm'\n",
    "CUSTOM_MODEL_NAME4='random_forest'\n",
    "\n",
    "CUSTOM_MODEL_NAME_PATH_1='./SavedModels/dense_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_2='./SavedModels/cnn_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_3='./SavedModels/lstm_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_4='./SavedModels/randomforest_0k.pkl'\n",
    "\n",
    "custom_model1 = Network()\n",
    "custom_model1.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_1+\"/pytorch_model.bin\"))\n",
    "\n",
    "custom_model2 = CNN1D()\n",
    "custom_model2.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_2+\"/pytorch_model.bin\"))\n",
    "\n",
    "custom_model3 = RNNModel()\n",
    "custom_model3.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_3+\"/pytorch_model.bin\"))\n",
    "\n",
    "with open(CUSTOM_MODEL_NAME_PATH_4, 'rb') as file:\n",
    "    custom_model4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 200)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "'''Preparing custom data'''\n",
    "\n",
    "with open('datasets/subtaskA_glove_train_dev_monolingual.pkl', 'rb') as f:\n",
    "    loaded_datasets = pickle.load(f)\n",
    "\n",
    "# Accessing loaded datasets\n",
    "loaded_train_x = loaded_datasets['train_x']\n",
    "loaded_train_y = loaded_datasets['train_y']\n",
    "loaded_dev_x = loaded_datasets['dev_x']\n",
    "loaded_dev_y = loaded_datasets['dev_y']\n",
    "\n",
    "print(loaded_dev_x.shape)\n",
    "print(loaded_dev_y.shape)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'input_ids': self.X[index], 'labels': self.y[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class DataCnn(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'x': self.X[index], 'label': self.y[index], 'label_ids': index}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "denseData=Data(loaded_dev_x, loaded_dev_y.values)\n",
    "cnnData=DataCnn(loaded_dev_x, loaded_dev_y.values)\n",
    "\n",
    "\n",
    "loaded_dev_y=loaded_dev_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Getting predictions from custom models'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "'''Dense'''\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset=denseData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model1.eval()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "custom_model1.to(device)\n",
    "\n",
    "# Container to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_data = batch['input_ids'].to(device)  # Moving data to device\n",
    "        labels = batch['labels'].to(device)  # This line is not necessary if you're only doing predictions, but move to device if you use them\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model1(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_predictions.extend(preds.cpu().numpy())  # Moving predictions back to cpu before converting to numpy\n",
    "\n",
    "predictions_dense=all_predictions\n",
    "\n",
    "'''CNN'''\n",
    "custom_model2 = custom_model2.to(device)\n",
    "# Create DataLoader for the CNN data\n",
    "cnn_data_loader = DataLoader(dataset=cnnData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model2.eval()\n",
    "\n",
    "# Container to store predictions\n",
    "all_cnn_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in cnn_data_loader:\n",
    "        input_data = batch['x'].to(device)  # Moving data to device\n",
    "        labels = batch['label'].to(device)  # Move to device if you use them, not necessary for only predictions\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model2(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_cnn_predictions.extend(preds.cpu().numpy())  # Moving predictions back to CPU before converting to numpy\n",
    "predictions_cnn=all_cnn_predictions\n",
    "\n",
    "'''LSTM'''\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset=denseData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model3.eval()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "custom_model3.to(device)\n",
    "\n",
    "# Container to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_data = batch['input_ids'].to(device)  # Moving data to device\n",
    "        labels = batch['labels'].to(device)  # This line is not necessary if you're only doing predictions, but move to device if you use them\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model3(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_predictions.extend(preds.cpu().numpy())  # Moving predictions back to cpu before converting to numpy\n",
    "\n",
    "predictions_lstm=all_predictions\n",
    "\n",
    "predictions_randomforest=custom_model4.predict(loaded_dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced DataFrame:\n",
      "label\n",
      "1    2500\n",
      "0    2500\n",
      "Name: count, dtype: int64\n",
      "[1 1 1 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "'''Loading data'''\n",
    "\n",
    "import pandas as pd,os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "SAMPLES_TO_TRAIN=5000\n",
    "\n",
    "df = pd.read_json(os.getcwd()+'/datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "test_df=df\n",
    "\n",
    "# Print the balanced DataFrame\n",
    "print(\"\\nBalanced DataFrame:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with pipe1:   0%|          | 8/5000 [00:00<01:07, 73.97it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Processing with pipe1: 100%|██████████| 5000/5000 [00:43<00:00, 115.88it/s]\n",
      "Processing with pipe2: 100%|██████████| 5000/5000 [02:15<00:00, 36.78it/s]\n",
      "Processing with pipe3: 100%|██████████| 5000/5000 [00:43<00:00, 114.78it/s]\n",
      "Processing with pipe4: 100%|██████████| 5000/5000 [01:21<00:00, 61.30it/s]\n",
      "Processing with pipe5: 100%|██████████| 5000/5000 [00:44<00:00, 113.02it/s]\n",
      "Processing with pipe6: 100%|██████████| 5000/5000 [00:44<00:00, 112.11it/s]\n"
     ]
    }
   ],
   "source": [
    "'''Getting predictions from transfer models'''\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "results1 = [pipe1(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe1\")]\n",
    "results2 = [pipe2(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe2\")]\n",
    "results3 = [pipe3(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe3\")]\n",
    "results4 = [pipe4(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe4\")]\n",
    "results5 = [pipe5(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe5\")]\n",
    "results6 = [pipe6(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=\"Processing with pipe6\")]\n",
    "\n",
    "labels1 = [0 if item['label'] == 'LABEL_0' else 1 for d in results1 for item in d]\n",
    "scores1 = [item['score'] for d in results1 for item in d]\n",
    "\n",
    "labels2 = [0 if item['label'] == 'LABEL_0' else 1 for d in results2 for item in d]\n",
    "scores2 = [item['score'] for d in results2 for item in d]\n",
    "\n",
    "labels3 = [0 if item['label'] == 'LABEL_0' else 1 for d in results3 for item in d]\n",
    "scores3 = [item['score'] for d in results3 for item in d]\n",
    "\n",
    "labels4 = [0 if item['label'] == 'LABEL_0' else 1 for d in results4 for item in d]\n",
    "scores4 = [item['score'] for d in results4 for item in d]\n",
    "\n",
    "labels5 = [0 if item['label'] == 'LABEL_0' else 1 for d in results5 for item in d]\n",
    "scores5 = [item['score'] for d in results5 for item in d]\n",
    "\n",
    "labels6 = [0 if item['label'] == 'LABEL_0' else 1 for d in results6 for item in d]\n",
    "scores6 = [item['score'] for d in results6 for item in d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get metrics'''\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def getMetrics(predicted_labels, true_labels):\n",
    "    # Ensure the labels are numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "    auc = roc_auc_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "{'accuracy': 0.556, 'f1': 0.36170212765957444, 'precision': 0.6431492842535788, 'recall': 0.2516, 'auc': 0.556}\n",
      "cnn\n",
      "{'accuracy': 0.5634, 'f1': 0.3821115199547127, 'precision': 0.6534365924491772, 'recall': 0.27, 'auc': 0.5634}\n",
      "lstm\n",
      "{'accuracy': 0.5528, 'f1': 0.36836158192090396, 'precision': 0.6269230769230769, 'recall': 0.2608, 'auc': 0.5528}\n",
      "random_forest\n",
      "{'accuracy': 0.4932, 'f1': 0.28700056274620145, 'precision': 0.4838709677419355, 'recall': 0.204, 'auc': 0.49319999999999997}\n"
     ]
    }
   ],
   "source": [
    "print(CUSTOM_MODEL_NAME1)\n",
    "print(getMetrics(predictions_dense,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME2)\n",
    "print(getMetrics(predictions_cnn,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME3)\n",
    "print(getMetrics(predictions_lstm,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME4)\n",
    "print(getMetrics(predictions_randomforest,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "{'accuracy': 0.732, 'f1': 0.6903881700554528, 'precision': 0.8172866520787746, 'recall': 0.5976, 'auc': 0.732}\n",
      "microsoft/deberta-large\n",
      "{'accuracy': 0.6868, 'f1': 0.570958904109589, 'precision': 0.9060869565217391, 'recall': 0.4168, 'auc': 0.6868000000000001}\n",
      "roberta-base\n",
      "{'accuracy': 0.7944, 'f1': 0.7503642544924721, 'precision': 0.9548825710754018, 'recall': 0.618, 'auc': 0.7943999999999999}\n",
      "roberta-large\n",
      "{'accuracy': 0.839, 'f1': 0.8466958674538183, 'precision': 0.8080697928026173, 'recall': 0.8892, 'auc': 0.839}\n",
      "Hello-SimpleAI/chatgpt-detector-roberta\n",
      "{'accuracy': 0.5, 'f1': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0, 'auc': 0.5}\n",
      "roberta-base-openai-detector\n",
      "{'accuracy': 0.5, 'f1': 0.6666666666666666, 'precision': 0.5, 'recall': 1.0, 'auc': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(MODEL1)\n",
    "print(getMetrics(labels1,test_df['label'].tolist()))\n",
    "print(MODEL2)\n",
    "print(getMetrics(labels2,test_df['label'].tolist()))\n",
    "print(MODEL3)\n",
    "print(getMetrics(labels3,test_df['label'].tolist()))\n",
    "print(MODEL4)\n",
    "print(getMetrics(labels4,test_df['label'].tolist()))\n",
    "print(MODEL5)\n",
    "print(getMetrics(labels5,test_df['label'].tolist()))\n",
    "print(MODEL6)\n",
    "print(getMetrics(labels6,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 16)\n",
      "(1000, 16)\n",
      "{'accuracy': 0.914, 'f1': 0.9138276553106212, 'precision': 0.8958742632612967, 'recall': 0.9325153374233128, 'auc': 0.9143985689073512}\n"
     ]
    }
   ],
   "source": [
    "'''Complex Ensemble models'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "'''Random Forest'''\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Labels_Model1': labels1,\n",
    "    'Scores_Model1': scores1,\n",
    "    'Labels_Model2': labels2,\n",
    "    'Scores_Model2': scores2,\n",
    "    'Labels_Model3': labels3,\n",
    "    'Scores_Model3': scores3,\n",
    "    'Labels_Model4': labels4,\n",
    "    'Scores_Model4': scores4,\n",
    "    'Labels_Model5': labels5,\n",
    "    'Scores_Model5': scores5,\n",
    "    'Labels_Model6': labels6,\n",
    "    'Scores_Model6': scores6,\n",
    "    'Prediction_dense':predictions_dense,\n",
    "    'Prediction_cnn':predictions_cnn,\n",
    "    'Prediction_lstm':predictions_lstm,\n",
    "    'Prediction_randomforest':predictions_randomforest,\n",
    "})\n",
    "\n",
    "labels = test_df['label'].tolist()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Create a Random Forest Classifier and train it on the training data\n",
    "clf = RandomForestClassifier(n_estimators=350, random_state=42,min_samples_split=3,min_samples_leaf=1,max_depth=None)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(getMetrics(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9828, 'f1': 0.9828685258964143, 'precision': 0.9789682539682539, 'recall': 0.9868, 'auc': 0.9828}\n"
     ]
    }
   ],
   "source": [
    "finalPrediction = clf.predict(df)\n",
    "print(getMetrics(finalPrediction,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SavedModels/'+'ensemble_randomforest_dev.pkl', 'wb') as model_file:\n",
    "    pickle.dump(clf, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 350}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [300,325,350,375],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='f1')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train and predict using the best model\n",
    "best_grid = grid_search.best_estimator_\n",
    "y_pred = best_grid.predict(X_test)\n",
    "\n",
    "# before optimizing\n",
    "# 'accuracy': 0.899, 'f1': 0.8999008919722498\n",
    "# after\n",
    "# 'accuracy': 0.902, 'f1': 0.902970297029703\n",
    "# transder+custom\n",
    "# 'accuracy': 0.913, 'f1': 0.9130869130869131, 'precision': 0.892578125, 'recall': 0.934560327198364, 'auc': 0.9134641166324501\n",
    "# transder+custom+rf\n",
    "# 'accuracy': 0.914, 'f1': 0.9138276553106212, 'precision': 0.8958742632612967, 'recall': 0.9325153374233128, 'auc': 0.9143985689073512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
