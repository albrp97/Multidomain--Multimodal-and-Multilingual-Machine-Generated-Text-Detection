{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malberto-rodero557\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Import libraries'''\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, Trainer, TrainingArguments\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Variables and parameters'''\n",
    "\n",
    "SAMPLES_TO_TRAIN=10000\n",
    "\n",
    "N_LABELS=2\n",
    "MAX_LEN = 256\n",
    "EPOCHS=100\n",
    "PATIENCE=10\n",
    "LEARNING_RATE=.00005\n",
    "WEIGHT_DECAY=.01\n",
    "BATCH_SIZE=100\n",
    "METRIC_FOR_BEST_MODEL='eval_loss'\n",
    "if METRIC_FOR_BEST_MODEL=='eval_loss':\n",
    "    GREATER_IS_BETTER = False\n",
    "else:\n",
    "    GREATER_IS_BETTER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before balancing: (10000, 2)\n",
      "Dataset size after balancing: (9298, 1)\n",
      "Entried dropped: 702\n",
      "\n",
      "Balanced DataFrame:\n",
      "label\n",
      "0    4649\n",
      "1    4649\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''Preparing dataset'''\n",
    "\n",
    "df = pd.read_json(os.getcwd()+'/datasets/subtaskA_train_monolingual.jsonl', lines=True)\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "train_df=df.sample(round(SAMPLES_TO_TRAIN))\n",
    "test_train_df=df.sample(round(SAMPLES_TO_TRAIN*.2))\n",
    "\n",
    "df = pd.read_json(os.getcwd()+'/datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "val_df= df.sample(round(SAMPLES_TO_TRAIN*.2))\n",
    "test_dev_df= df.sample(round(SAMPLES_TO_TRAIN*.2))\n",
    "\n",
    "# we balance the training set\n",
    "print(f'Dataset size before balancing: {train_df.shape}')\n",
    "counts = train_df['label'].value_counts()\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "x_text, y = sampler.fit_resample(train_df[['text']], train_df['label'])\n",
    "\n",
    "print(f'Dataset size after balancing: {x_text.shape}')\n",
    "print(f'Entried dropped: {train_df.shape[0]-x_text.shape[0]}')\n",
    "\n",
    "# Create a new balanced DataFrame\n",
    "train_df = pd.DataFrame({'text': x_text['text'], 'label': y})\n",
    "\n",
    "# Print the balanced DataFrame\n",
    "print(\"\\nBalanced DataFrame:\")\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "'''loading glove'''\n",
    "embeddings_index={}\n",
    "with open('../OtherData/glove.6B.200d.txt','r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vectors=np.asarray(values[1:],'float32')\n",
    "        embeddings_index[word]=vectors\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9298/9298 [00:14<00:00, 645.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 200)\n",
      "\n",
      "Validation df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 852.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 200)\n",
      "\n",
      "Testing from training dataset df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 675.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 200)\n",
      "\n",
      "Testing from dev dataset df:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 903.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''glove building'''\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm \n",
    "\n",
    "def sent2vec(s):\n",
    "    \"\"\" Function Creates a normalized vector for the whole sentence\"\"\"\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(embeddings_index[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    if type(v) != np.ndarray:\n",
    "        return np.zeros(200)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "print('Training df:')\n",
    "train_x = np.array([sent2vec(x) for x in tqdm(train_df['text'])])\n",
    "print(train_x.shape)\n",
    "train_y=train_df['label']\n",
    "\n",
    "print('\\nValidation df:')\n",
    "val_x = np.array([sent2vec(x) for x in tqdm(val_df['text'])])\n",
    "print(val_x.shape)\n",
    "val_y=val_df['label']\n",
    "\n",
    "print('\\nTesting from training dataset df:')\n",
    "test_train_x = np.array([sent2vec(x) for x in tqdm(test_train_df['text'])])\n",
    "print(test_train_x.shape)\n",
    "test_train_y=test_train_df['label']\n",
    "\n",
    "print('\\nTesting from dev dataset df:')\n",
    "test_dev_x = np.array([sent2vec(x) for x in tqdm(test_dev_df['text'])])\n",
    "print(test_dev_x.shape)\n",
    "test_dev_y=test_dev_df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Preparing for training'''\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Fit the scaler to the training data and transform the data\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "val_x = scaler.transform(val_x)  # Note that we use the same scaler to transform the test data\n",
    "test_train_x = scaler.transform(test_train_x)\n",
    "test_dev_x = scaler.transform(test_dev_x)\n",
    "# If this scaler is going to be used later on for prediction it must be saved, for example with pickle\n",
    "import pickle\n",
    "\n",
    "# Save the trained scaler\n",
    "with open('scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9298, 200) (9298,) (2000, 200) (2000,)\n",
      "(2000, 200) (2000,) (2000, 200) (2000,)\n",
      "9298 2000\n",
      "2000 2000\n"
     ]
    }
   ],
   "source": [
    "'''creating custom dataset'''\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.features[idx],  # changed 'features' to 'x'\n",
    "            'label': self.labels[idx]  # changed 'labels' to 'label'\n",
    "        }\n",
    "\n",
    "# Verify the shape and type of the data\n",
    "print(train_x.shape, train_y.shape, val_x.shape, val_y.shape)\n",
    "print(test_train_x.shape, test_train_y.shape, test_dev_x.shape, test_dev_y.shape)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "\n",
    "test_train_x = torch.tensor(test_train_x, dtype=torch.float32)\n",
    "test_dev_x = torch.tensor(test_dev_x, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# now y\n",
    "train_y = torch.tensor(train_y.to_numpy(), dtype=torch.float32) if isinstance(train_y, pd.Series) else torch.tensor(train_y, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y.to_numpy(), dtype=torch.float32) if isinstance(val_y, pd.Series) else torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "test_train_y = torch.tensor(test_train_y.to_numpy(), dtype=torch.float32) if isinstance(test_train_y, pd.Series) else torch.tensor(test_train_y, dtype=torch.float32)\n",
    "test_dev_y = torch.tensor(test_dev_y.to_numpy(), dtype=torch.float32) if isinstance(test_dev_y, pd.Series) else torch.tensor(test_dev_y, dtype=torch.float32)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = CustomDataset(train_x, train_y)\n",
    "val_dataset = CustomDataset(val_x, val_y)\n",
    "test_train_dataset = CustomDataset(test_train_x, test_train_y)\n",
    "test_dev_dataset = CustomDataset(test_dev_x, test_dev_y)\n",
    "\n",
    "# Check the length of datasets\n",
    "print(len(train_dataset), len(val_dataset))\n",
    "print(len(test_train_dataset), len(test_dev_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''building custom model'''\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 200)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(100)\n",
    "        self.fc3 = nn.Linear(100, 100)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(100)\n",
    "        self.fc4 = nn.Linear(100, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = F.relu(self.batchnorm1(self.dropout1(self.fc1(x))))\n",
    "        x = F.relu(self.batchnorm2(self.dropout2(self.fc2(x))))\n",
    "        x = F.relu(self.batchnorm3(self.dropout3(self.fc3(x))))\n",
    "        logits = self.fc4(x)\n",
    "        outputs = self.sigmoid(logits)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = F.binary_cross_entropy(outputs, labels.unsqueeze(-1))\n",
    "            return loss, outputs\n",
    "        return outputs\n",
    "\n",
    "# Instantiate the model\n",
    "model = MyModel(input_dim=train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''metrics'''\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    auc = roc_auc_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define training arguments and initialize trainer'''\n",
    "\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    metric_for_best_model=METRIC_FOR_BEST_MODEL,\n",
    "    greater_is_better=GREATER_IS_BETTER,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1500,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=False,\n",
    "    logging_first_step=False,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 79/9300 [00:00<00:23, 389.30it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  2%|▏         | 158/9300 [00:00<00:26, 341.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1568818092346191, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0265, 'eval_samples_per_second': 75370.698, 'eval_steps_per_second': 753.707, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  2%|▏         | 232/9300 [00:00<00:27, 327.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1559313535690308, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.028, 'eval_samples_per_second': 71301.385, 'eval_steps_per_second': 713.014, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 271/9300 [00:00<00:26, 344.76it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  4%|▎         | 345/9300 [00:01<00:27, 328.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1506930589675903, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0305, 'eval_samples_per_second': 65511.433, 'eval_steps_per_second': 655.114, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  4%|▍         | 416/9300 [00:01<00:27, 318.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1889064311981201, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0285, 'eval_samples_per_second': 70096.078, 'eval_steps_per_second': 700.961, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 454/9300 [00:01<00:26, 333.61it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  6%|▌         | 530/9300 [00:01<00:26, 334.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1270395517349243, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0331, 'eval_samples_per_second': 60428.82, 'eval_steps_per_second': 604.288, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  7%|▋         | 605/9300 [00:01<00:26, 333.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1756553649902344, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.029, 'eval_samples_per_second': 68887.257, 'eval_steps_per_second': 688.873, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 644/9300 [00:01<00:24, 348.81it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  8%|▊         | 720/9300 [00:02<00:24, 344.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1502429246902466, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0271, 'eval_samples_per_second': 73858.984, 'eval_steps_per_second': 738.59, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  9%|▊         | 797/9300 [00:02<00:24, 340.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1706552505493164, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0245, 'eval_samples_per_second': 81575.059, 'eval_steps_per_second': 815.751, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "  9%|▉         | 880/9300 [00:02<00:24, 346.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1813157796859741, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.026, 'eval_samples_per_second': 76893.395, 'eval_steps_per_second': 768.934, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 921/9300 [00:02<00:23, 361.93it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 11%|█         | 997/9300 [00:03<00:24, 345.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1832988262176514, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0275, 'eval_samples_per_second': 72678.981, 'eval_steps_per_second': 726.79, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 12%|█▏        | 1074/9300 [00:03<00:24, 334.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2138298749923706, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0298, 'eval_samples_per_second': 67172.813, 'eval_steps_per_second': 671.728, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1114/9300 [00:03<00:23, 350.02it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 13%|█▎        | 1189/9300 [00:03<00:23, 340.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1950109004974365, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0283, 'eval_samples_per_second': 70777.398, 'eval_steps_per_second': 707.774, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 14%|█▎        | 1259/9300 [00:03<00:25, 318.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2060163021087646, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0266, 'eval_samples_per_second': 75273.984, 'eval_steps_per_second': 752.74, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1297/9300 [00:03<00:24, 333.38it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 15%|█▍        | 1371/9300 [00:04<00:23, 333.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2148991823196411, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0279, 'eval_samples_per_second': 71720.798, 'eval_steps_per_second': 717.208, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      " 15%|█▌        | 1395/9300 [00:04<00:24, 326.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2498315572738647, 'eval_accuracy': 0.504, 'eval_f1': 0.0, 'eval_auc': 0.5, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_runtime': 0.0275, 'eval_samples_per_second': 72678.981, 'eval_steps_per_second': 726.79, 'epoch': 15.0}\n",
      "{'train_runtime': 4.2726, 'train_samples_per_second': 217619.434, 'train_steps_per_second': 2176.662, 'train_loss': 0.3092324533770161, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1395, training_loss=0.3092324533770161, metrics={'train_runtime': 4.2726, 'train_samples_per_second': 217619.434, 'train_steps_per_second': 2176.662, 'train_loss': 0.3092324533770161, 'epoch': 15.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 20/20 [00:00<00:00, 722.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.412348210811615,\n",
       " 'eval_accuracy': 0.5315,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_auc': 0.5,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_runtime': 0.0297,\n",
       " 'eval_samples_per_second': 67253.594,\n",
       " 'eval_steps_per_second': 672.536,\n",
       " 'epoch': 99.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 20/20 [00:00<00:00, 848.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.412348210811615,\n",
       " 'eval_accuracy': 0.5315,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_auc': 0.5,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_runtime': 0.0266,\n",
       " 'eval_samples_per_second': 75238.876,\n",
       " 'eval_steps_per_second': 752.389,\n",
       " 'epoch': 99.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "100%|██████████| 20/20 [00:00<00:00, 792.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.175024390220642,\n",
       " 'eval_accuracy': 0.5065,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_auc': 0.5,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_runtime': 0.0282,\n",
       " 'eval_samples_per_second': 70829.39,\n",
       " 'eval_steps_per_second': 708.294,\n",
       " 'epoch': 99.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dev_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
