{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL1='bert-base-uncased'\n",
    "MODEL2='microsoft/deberta-large'\n",
    "MODEL3='roberta-base'\n",
    "MODEL4='roberta-large'\n",
    "MODEL5='Hello-SimpleAI/chatgpt-detector-roberta'\n",
    "MODEL6='roberta-base-openai-detector'\n",
    "\n",
    "MODEL7='Hello-SimpleAI/chatgpt-detector-roberta'\n",
    "MODEL8='Hello-SimpleAI/chatgpt-detector-roberta'\n",
    "\n",
    "MODEL_PATH1='SavedModels/bert-base-uncased20k'\n",
    "MODEL_PATH2='SavedModels/deberta-large5k'\n",
    "MODEL_PATH3='SavedModels/roberta-base20k'\n",
    "MODEL_PATH4='SavedModels/roberta-large5k'\n",
    "MODEL_PATH5='SavedModels/chatgpt-detector-roberta5k'\n",
    "MODEL_PATH6='SavedModels/roberta-base-openai-detector20k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load tokenizers and models'''\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(MODEL1)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH1)\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(MODEL2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH2)\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(MODEL3)\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH3)\n",
    "\n",
    "tokenizer4 = AutoTokenizer.from_pretrained(MODEL4)\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH4)\n",
    "\n",
    "tokenizer5 = AutoTokenizer.from_pretrained(MODEL5)\n",
    "model5 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH5)\n",
    "\n",
    "tokenizer6 = AutoTokenizer.from_pretrained(MODEL6)\n",
    "model6 = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH6)\n",
    "\n",
    "pipe1 = pipeline(\"text-classification\", model=model1, tokenizer=tokenizer1, device=0)\n",
    "pipe2 = pipeline(\"text-classification\", model=model2, tokenizer=tokenizer2, device=0)\n",
    "pipe3 = pipeline(\"text-classification\", model=model3, tokenizer=tokenizer3, device=0)\n",
    "pipe4 = pipeline(\"text-classification\", model=model4, tokenizer=tokenizer4, device=0)\n",
    "pipe5 = pipeline(\"text-classification\", model=model5, tokenizer=tokenizer5, device=0)\n",
    "pipe6 = pipeline(\"text-classification\", model=model6, tokenizer=tokenizer6, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Custom model architectures'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "input_dim = 200\n",
    "\n",
    "# number of classes (unique of y)\n",
    "output_dim = 2\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.linear4 = nn.Linear(256, output_dim)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        x1 = F.leaky_relu(self.linear1(input_ids))\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.dropout1(x1)\n",
    "        \n",
    "        x2 = F.leaky_relu(self.linear2(x1))\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.dropout2(x2)\n",
    "        \n",
    "        # Adding the first skip connection\n",
    "        x2 += x1\n",
    "        \n",
    "        x3 = F.leaky_relu(self.linear3(x2))\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.dropout3(x3)\n",
    "        \n",
    "        x4 = self.linear4(x3)\n",
    "        \n",
    "        outputs = (x4,)\n",
    "        if labels is not None:\n",
    "            loss = self.loss(x4, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "            \n",
    "        return (outputs if len(outputs) > 1 else outputs[0])\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=100, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        self.conv2 = nn.Conv1d(in_channels=100, out_channels=150, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(150)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(150 * 200, 256)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Flatten the output for the dense layer\n",
    "        x = torch.flatten(x, 1) \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(x, labels)\n",
    "            return loss, x\n",
    "        \n",
    "        return x\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_dim, 512, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.lstm2 = nn.LSTM(512, 512, batch_first=True)\n",
    "        self.ln2 = nn.LayerNorm(512)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc = nn.Linear(512, output_dim)\n",
    "        \n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        # print(f\"Input shape: {input_ids.shape}\")\n",
    "        \n",
    "        x, _ = self.lstm1(input_ids)\n",
    "        # print(f\"After LSTM1: {x.shape}\")\n",
    "\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # print(f\"Before LSTM2: {x.shape}\")\n",
    "        \n",
    "        x, _ = self.lstm2(x)\n",
    "        # print(f\"After LSTM2: {x.shape}\")\n",
    "\n",
    "        x = self.ln2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        # print(f\"Output shape: {x.shape}\")\n",
    "        \n",
    "        outputs = (x,)\n",
    "        if labels is not None:\n",
    "            loss = self.loss(x, labels)\n",
    "            outputs = (loss,) + outputs\n",
    "            \n",
    "        return (outputs if len(outputs) > 1 else outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Custom model preparation'''\n",
    "\n",
    "CUSTOM_MODEL_NAME1='dense'\n",
    "CUSTOM_MODEL_NAME2='cnn'\n",
    "CUSTOM_MODEL_NAME3='lstm'\n",
    "CUSTOM_MODEL_NAME4='random_forest'\n",
    "\n",
    "CUSTOM_MODEL_NAME_PATH_1='./SavedModels/dense_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_2='./SavedModels/cnn_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_3='./SavedModels/lstm_0k'\n",
    "CUSTOM_MODEL_NAME_PATH_4='./SavedModels/randomforest_0k.pkl'\n",
    "\n",
    "custom_model1 = Network()\n",
    "custom_model1.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_1+\"/pytorch_model.bin\"))\n",
    "\n",
    "custom_model2 = CNN1D()\n",
    "custom_model2.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_2+\"/pytorch_model.bin\"))\n",
    "\n",
    "custom_model3 = RNNModel()\n",
    "custom_model3.load_state_dict(torch.load(CUSTOM_MODEL_NAME_PATH_3+\"/pytorch_model.bin\"))\n",
    "\n",
    "with open(CUSTOM_MODEL_NAME_PATH_4, 'rb') as file:\n",
    "    custom_model4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 200)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "'''Preparing custom data'''\n",
    "\n",
    "with open('datasets/subtaskA_glove_train_dev_monolingual.pkl', 'rb') as f:\n",
    "    loaded_datasets = pickle.load(f)\n",
    "\n",
    "# Accessing loaded datasets\n",
    "loaded_train_x = loaded_datasets['train_x']\n",
    "loaded_train_y = loaded_datasets['train_y']\n",
    "loaded_dev_x = loaded_datasets['dev_x']\n",
    "loaded_dev_y = loaded_datasets['dev_y']\n",
    "\n",
    "print(loaded_dev_x.shape)\n",
    "print(loaded_dev_y.shape)\n",
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X = torch.from_numpy(X_train.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'input_ids': self.X[index], 'labels': self.y[index]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class DataCnn(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        self.len = len(X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'x': self.X[index], 'label': self.y[index], 'label_ids': index}\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "denseData=Data(loaded_dev_x, loaded_dev_y.values)\n",
    "cnnData=DataCnn(loaded_dev_x, loaded_dev_y.values)\n",
    "\n",
    "loaded_dev_y=loaded_dev_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Getting predictions from custom models'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "'''Dense'''\n",
    "\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset=denseData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model1.eval()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "custom_model1.to(device)\n",
    "\n",
    "# Container to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_data = batch['input_ids'].to(device)  # Moving data to device\n",
    "        labels = batch['labels'].to(device)  # This line is not necessary if you're only doing predictions, but move to device if you use them\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model1(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_predictions.extend(preds.cpu().numpy())  # Moving predictions back to cpu before converting to numpy\n",
    "\n",
    "predictions_dense=all_predictions\n",
    "\n",
    "'''CNN'''\n",
    "custom_model2 = custom_model2.to(device)\n",
    "# Create DataLoader for the CNN data\n",
    "cnn_data_loader = DataLoader(dataset=cnnData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model2.eval()\n",
    "\n",
    "# Container to store predictions\n",
    "all_cnn_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in cnn_data_loader:\n",
    "        input_data = batch['x'].to(device)  # Moving data to device\n",
    "        labels = batch['label'].to(device)  # Move to device if you use them, not necessary for only predictions\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model2(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_cnn_predictions.extend(preds.cpu().numpy())  # Moving predictions back to CPU before converting to numpy\n",
    "predictions_cnn=all_cnn_predictions\n",
    "\n",
    "'''LSTM'''\n",
    "# Create a DataLoader\n",
    "data_loader = DataLoader(dataset=denseData, batch_size=32, shuffle=False)  # Adjust batch size as needed\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "custom_model3.eval()\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move model to the appropriate device\n",
    "custom_model3.to(device)\n",
    "\n",
    "# Container to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate over the DataLoader to get predictions\n",
    "with torch.no_grad():\n",
    "    for batch in data_loader:\n",
    "        input_data = batch['input_ids'].to(device)  # Moving data to device\n",
    "        labels = batch['labels'].to(device)  # This line is not necessary if you're only doing predictions, but move to device if you use them\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = custom_model3(input_data)\n",
    "\n",
    "        # Get the predicted labels (assuming a classification task here)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "        # Store predictions\n",
    "        all_predictions.extend(preds.cpu().numpy())  # Moving predictions back to cpu before converting to numpy\n",
    "\n",
    "predictions_lstm=all_predictions\n",
    "\n",
    "predictions_randomforest=custom_model4.predict(loaded_dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5000 non-null   object\n",
      " 1   label   5000 non-null   int64 \n",
      " 2   model   5000 non-null   object\n",
      " 3   source  5000 non-null   object\n",
      " 4   id      5000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 195.4+ KB\n",
      "None\n",
      "\n",
      "label\n",
      "1    2500\n",
      "0    2500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "bloomz    2500\n",
      "human     2500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "source\n",
      "wikihow      1000\n",
      "wikipedia    1000\n",
      "reddit       1000\n",
      "arxiv        1000\n",
      "peerread     1000\n",
      "Name: count, dtype: int64\n",
      "                                                   text  label   model  \\\n",
      "3322  We present an explicit expression for the effe...      1  bloomz   \n",
      "3565    Dim radio-quiet neutron star (DRQNS) 1E 1207...      0   human   \n",
      "4457  The authors present an interesting approach th...      1  bloomz   \n",
      "2598  its not water that makes skin stay moist - its...      0   human   \n",
      "4612  A few issues with this paper:\\n1- I find findi...      0   human   \n",
      "\n",
      "        source    id  \n",
      "3322     arxiv  3322  \n",
      "3565     arxiv  3565  \n",
      "4457  peerread  4457  \n",
      "2598    reddit  2598  \n",
      "4612  peerread  4612  \n",
      "\n",
      "Balanced DataFrame:\n",
      "label\n",
      "1    2500\n",
      "0    2500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "'''Loading data'''\n",
    "\n",
    "import pandas as pd,os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "df = pd.read_json(os.getcwd()+'/datasets/subtaskA_dev_monolingual.jsonl', lines=True)\n",
    "print(df.info())\n",
    "print(f'''\\n{df['label'].value_counts()}''')\n",
    "print(f'''\\n{df['model'].value_counts()}''')\n",
    "print(f'''\\n{df['source'].value_counts()}''')\n",
    "print(df.sample(5))\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "\n",
    "test_df=df\n",
    "SAMPLES_TO_TRAIN=test_df.shape[0]\n",
    "\n",
    "# Print the balanced DataFrame\n",
    "print(\"\\nBalanced DataFrame:\")\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with bert-base-uncased:   0%|          | 8/5000 [00:00<01:03, 78.60it/s]c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Processing with bert-base-uncased: 100%|██████████| 5000/5000 [00:37<00:00, 134.68it/s]\n",
      "Processing with microsoft/deberta-large: 100%|██████████| 5000/5000 [02:27<00:00, 33.94it/s]\n",
      "Processing with roberta-base: 100%|██████████| 5000/5000 [00:39<00:00, 126.73it/s]\n",
      "Processing with roberta-large: 100%|██████████| 5000/5000 [01:06<00:00, 75.34it/s]\n",
      "Processing with Hello-SimpleAI/chatgpt-detector-roberta: 100%|██████████| 5000/5000 [00:39<00:00, 127.76it/s]\n",
      "Processing with roberta-base-openai-detector: 100%|██████████| 5000/5000 [00:38<00:00, 130.41it/s]\n"
     ]
    }
   ],
   "source": [
    "'''Getting predictions from transfer models'''\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "results1 = [pipe1(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL1}\")]\n",
    "results2 = [pipe2(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL2}\")]\n",
    "results3 = [pipe3(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL3}\")]\n",
    "results4 = [pipe4(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL4}\")]\n",
    "results5 = [pipe5(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL5}\")]\n",
    "results6 = [pipe6(text, truncation=True, max_length=256) for text in tqdm(test_texts, desc=f\"Processing with {MODEL6}\")]\n",
    "\n",
    "labels1 = [0 if item['label'] == 'LABEL_0' else 1 for d in results1 for item in d]\n",
    "scores1 = [item['score'] for d in results1 for item in d]\n",
    "\n",
    "labels2 = [0 if item['label'] == 'LABEL_0' else 1 for d in results2 for item in d]\n",
    "scores2 = [item['score'] for d in results2 for item in d]\n",
    "\n",
    "labels3 = [0 if item['label'] == 'LABEL_0' else 1 for d in results3 for item in d]\n",
    "scores3 = [item['score'] for d in results3 for item in d]\n",
    "\n",
    "labels4 = [0 if item['label'] == 'LABEL_0' else 1 for d in results4 for item in d]\n",
    "scores4 = [item['score'] for d in results4 for item in d]\n",
    "\n",
    "labels5 = [0 if item['label'] == 'Human' else 1 for d in results5 for item in d]\n",
    "scores5 = [item['score'] for d in results5 for item in d]\n",
    "\n",
    "labels6 = [1 if item['label'] == 'Real' else 0 for d in results6 for item in d]\n",
    "scores6 = [item['score'] for d in results6 for item in d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get metrics'''\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "def getMetrics(predicted_labels, true_labels):\n",
    "    # Ensure the labels are numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "    precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "    auc = roc_auc_score(true_labels, predicted_labels)\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': cm.tolist()  # Convert confusion matrix to a list for JSON serialization\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense\n",
      "{'accuracy': 0.556, 'f1': 0.36170212765957444, 'precision': 0.6431492842535788, 'recall': 0.2516, 'auc': 0.556, 'confusion_matrix': [[2151, 349], [1871, 629]]}\n",
      "cnn\n",
      "{'accuracy': 0.5634, 'f1': 0.3821115199547127, 'precision': 0.6534365924491772, 'recall': 0.27, 'auc': 0.5634, 'confusion_matrix': [[2142, 358], [1825, 675]]}\n",
      "lstm\n",
      "{'accuracy': 0.5528, 'f1': 0.36836158192090396, 'precision': 0.6269230769230769, 'recall': 0.2608, 'auc': 0.5528, 'confusion_matrix': [[2112, 388], [1848, 652]]}\n",
      "random_forest\n",
      "{'accuracy': 0.4932, 'f1': 0.28700056274620145, 'precision': 0.4838709677419355, 'recall': 0.204, 'auc': 0.49319999999999997, 'confusion_matrix': [[1956, 544], [1990, 510]]}\n"
     ]
    }
   ],
   "source": [
    "print(CUSTOM_MODEL_NAME1)\n",
    "print(getMetrics(predictions_dense,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME2)\n",
    "print(getMetrics(predictions_cnn,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME3)\n",
    "print(getMetrics(predictions_lstm,test_df['label'].tolist()))\n",
    "print(CUSTOM_MODEL_NAME4)\n",
    "print(getMetrics(predictions_randomforest,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "{'accuracy': 0.6902, 'f1': 0.5852744310575636, 'precision': 0.8850202429149797, 'recall': 0.4372, 'auc': 0.6902, 'confusion_matrix': [[2358, 142], [1407, 1093]]}\n",
      "microsoft/deberta-large\n",
      "{'accuracy': 0.6868, 'f1': 0.570958904109589, 'precision': 0.9060869565217391, 'recall': 0.4168, 'auc': 0.6868000000000001, 'confusion_matrix': [[2392, 108], [1458, 1042]]}\n",
      "roberta-base\n",
      "{'accuracy': 0.6556, 'f1': 0.49412455934195065, 'precision': 0.9303097345132744, 'recall': 0.3364, 'auc': 0.6556, 'confusion_matrix': [[2437, 63], [1659, 841]]}\n",
      "roberta-large\n",
      "{'accuracy': 0.839, 'f1': 0.8466958674538183, 'precision': 0.8080697928026173, 'recall': 0.8892, 'auc': 0.839, 'confusion_matrix': [[1972, 528], [277, 2223]]}\n",
      "Hello-SimpleAI/chatgpt-detector-roberta\n",
      "{'accuracy': 0.6998, 'f1': 0.6106355382619973, 'precision': 0.8686346863468635, 'recall': 0.4708, 'auc': 0.6998, 'confusion_matrix': [[2322, 178], [1323, 1177]]}\n",
      "roberta-base-openai-detector\n",
      "{'accuracy': 0.636, 'f1': 0.44137507673419285, 'precision': 0.9485488126649076, 'recall': 0.2876, 'auc': 0.636, 'confusion_matrix': [[2461, 39], [1781, 719]]}\n"
     ]
    }
   ],
   "source": [
    "print(MODEL1)\n",
    "print(getMetrics(labels1,test_df['label'].tolist()))\n",
    "print(MODEL2)\n",
    "print(getMetrics(labels2,test_df['label'].tolist()))\n",
    "print(MODEL3)\n",
    "print(getMetrics(labels3,test_df['label'].tolist()))\n",
    "print(MODEL4)\n",
    "print(getMetrics(labels4,test_df['label'].tolist()))\n",
    "print(MODEL5)\n",
    "print(getMetrics(labels5,test_df['label'].tolist()))\n",
    "print(MODEL6)\n",
    "print(getMetrics(labels6,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6288, 'f1': 0.42431761786600497, 'precision': 0.9447513812154696, 'recall': 0.2736, 'auc': 0.6288, 'confusion_matrix': [[2460, 40], [1816, 684]]}\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    f'Labels_{MODEL1}': labels1,\n",
    "    f'Scores_{MODEL1}': scores1,\n",
    "    f'Labels_{MODEL2}': labels2,\n",
    "    f'Scores_{MODEL2}': scores2,\n",
    "    f'Labels_{MODEL3}': labels3,\n",
    "    f'Scores_{MODEL3}': scores3,\n",
    "    f'Labels_{MODEL4}': labels4,\n",
    "    f'Scores_{MODEL4}': scores4,\n",
    "    f'Labels_{MODEL5}': labels5,\n",
    "    f'Scores_{MODEL5}': scores5,\n",
    "    f'Labels_{MODEL6}': labels6,\n",
    "    f'Scores_{MODEL6}': scores6,\n",
    "    'Prediction_dense':predictions_dense,\n",
    "    'Prediction_cnn':predictions_cnn,\n",
    "    'Prediction_lstm':predictions_lstm,\n",
    "    'Prediction_randomforest':predictions_randomforest,\n",
    "})\n",
    "\n",
    "labels = test_df['label'].tolist()\n",
    "\n",
    "with open('SavedModels/ensemble_randomforest_train.pkl', 'rb') as file:\n",
    "        ensembleModel = pickle.load(file)\n",
    "\n",
    "finalPrediction = ensembleModel.predict(df)\n",
    "\n",
    "print(getMetrics(finalPrediction,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels_bert-base-uncased</th>\n",
       "      <th>Scores_bert-base-uncased</th>\n",
       "      <th>Labels_microsoft/deberta-large</th>\n",
       "      <th>Scores_microsoft/deberta-large</th>\n",
       "      <th>Labels_roberta-base</th>\n",
       "      <th>Scores_roberta-base</th>\n",
       "      <th>Labels_roberta-large</th>\n",
       "      <th>Scores_roberta-large</th>\n",
       "      <th>Labels_Hello-SimpleAI/chatgpt-detector-roberta</th>\n",
       "      <th>Scores_Hello-SimpleAI/chatgpt-detector-roberta</th>\n",
       "      <th>Labels_roberta-base-openai-detector</th>\n",
       "      <th>Scores_roberta-base-openai-detector</th>\n",
       "      <th>Prediction_dense</th>\n",
       "      <th>Prediction_cnn</th>\n",
       "      <th>Prediction_lstm</th>\n",
       "      <th>Prediction_randomforest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.986458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997903</td>\n",
       "      <td>1</td>\n",
       "      <td>0.916230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990715</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804012</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991061</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749325</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.990361</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809746</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.947833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998468</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982552</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996642</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997943</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998435</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.996838</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999982</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998399</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982581</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977234</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997955</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Labels_bert-base-uncased  Scores_bert-base-uncased  \\\n",
       "0                            1                  0.986458   \n",
       "1                            1                  0.990715   \n",
       "2                            1                  0.990361   \n",
       "3                            0                  0.947833   \n",
       "4                            1                  0.766751   \n",
       "...                        ...                       ...   \n",
       "4995                         0                  0.996642   \n",
       "4996                         0                  0.998859   \n",
       "4997                         0                  0.996838   \n",
       "4998                         0                  0.998399   \n",
       "4999                         0                  0.998487   \n",
       "\n",
       "      Labels_microsoft/deberta-large  Scores_microsoft/deberta-large  \\\n",
       "0                                  0                        0.997726   \n",
       "1                                  1                        0.804012   \n",
       "2                                  0                        0.999279   \n",
       "3                                  0                        0.999961   \n",
       "4                                  1                        0.999913   \n",
       "...                              ...                             ...   \n",
       "4995                               0                        0.999983   \n",
       "4996                               0                        0.999985   \n",
       "4997                               0                        0.999982   \n",
       "4998                               0                        0.999973   \n",
       "4999                               0                        0.999879   \n",
       "\n",
       "      Labels_roberta-base  Scores_roberta-base  Labels_roberta-large  \\\n",
       "0                       0             0.999538                     0   \n",
       "1                       1             0.991061                     1   \n",
       "2                       0             0.998842                     1   \n",
       "3                       0             0.997465                     1   \n",
       "4                       1             0.999739                     1   \n",
       "...                   ...                  ...                   ...   \n",
       "4995                    0             0.999532                     1   \n",
       "4996                    0             0.999540                     0   \n",
       "4997                    0             0.999541                     0   \n",
       "4998                    0             0.999525                     1   \n",
       "4999                    1             0.977234                     0   \n",
       "\n",
       "      Scores_roberta-large  Labels_Hello-SimpleAI/chatgpt-detector-roberta  \\\n",
       "0                 0.997903                                               1   \n",
       "1                 0.983358                                               1   \n",
       "2                 0.809746                                               1   \n",
       "3                 0.980866                                               0   \n",
       "4                 0.982552                                               0   \n",
       "...                    ...                                             ...   \n",
       "4995              0.983148                                               0   \n",
       "4996              0.997943                                               0   \n",
       "4997              0.997883                                               0   \n",
       "4998              0.982581                                               0   \n",
       "4999              0.997955                                               0   \n",
       "\n",
       "      Scores_Hello-SimpleAI/chatgpt-detector-roberta  \\\n",
       "0                                           0.916230   \n",
       "1                                           0.749325   \n",
       "2                                           0.996288   \n",
       "3                                           0.998468   \n",
       "4                                           0.998502   \n",
       "...                                              ...   \n",
       "4995                                        0.998445   \n",
       "4996                                        0.998435   \n",
       "4997                                        0.998489   \n",
       "4998                                        0.998454   \n",
       "4999                                        0.998433   \n",
       "\n",
       "      Labels_roberta-base-openai-detector  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "...                                   ...   \n",
       "4995                                    0   \n",
       "4996                                    0   \n",
       "4997                                    0   \n",
       "4998                                    0   \n",
       "4999                                    0   \n",
       "\n",
       "      Scores_roberta-base-openai-detector  Prediction_dense  Prediction_cnn  \\\n",
       "0                                0.999977                 1               1   \n",
       "1                                0.999977                 0               0   \n",
       "2                                0.999977                 0               0   \n",
       "3                                0.999977                 0               1   \n",
       "4                                0.999977                 1               1   \n",
       "...                                   ...               ...             ...   \n",
       "4995                             0.999977                 0               0   \n",
       "4996                             0.999977                 0               0   \n",
       "4997                             0.999977                 0               0   \n",
       "4998                             0.999977                 0               0   \n",
       "4999                             0.999977                 0               0   \n",
       "\n",
       "      Prediction_lstm  Prediction_randomforest  \n",
       "0                   1                        0  \n",
       "1                   0                        0  \n",
       "2                   0                        0  \n",
       "3                   0                        0  \n",
       "4                   0                        0  \n",
       "...               ...                      ...  \n",
       "4995                0                        0  \n",
       "4996                0                        0  \n",
       "4997                0                        0  \n",
       "4998                0                        0  \n",
       "4999                0                        0  \n",
       "\n",
       "[5000 rows x 16 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# majority voting\n",
    "# mean nosecuanto\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;rf&#x27;,\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               (&#x27;svc&#x27;, SVC(probability=True)),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;rf&#x27;,\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               (&#x27;svc&#x27;, SVC(probability=True)),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=3, n_estimators=350, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               ('svc', SVC(probability=True)),\n",
       "                               ('knn', KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assume df is your DataFrame and labels is your target array\n",
    "X = df\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base learners\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=350, random_state=42, min_samples_split=3, min_samples_leaf=1, max_depth=None)),\n",
    "    ('svc', SVC(probability=True)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Initialize Stacking Classifier with the Meta Learner\n",
    "stack_clf = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression(), cv=5)\n",
    "\n",
    "# Fit the model on your data\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use stack_clf to make new predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.891, 'f1': 0.8913260219341974, 'precision': 0.8696498054474708, 'recall': 0.9141104294478528, 'auc': 0.8914974847826347, 'confusion_matrix': [[444, 67], [42, 447]]}\n"
     ]
    }
   ],
   "source": [
    "finalPrediction = stack_clf.predict(X_test)\n",
    "\n",
    "print(getMetrics(finalPrediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;rf&#x27;,\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               (&#x27;svc&#x27;, SVC(probability=True)),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(cv=5,\n",
       "                   estimators=[(&#x27;rf&#x27;,\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               (&#x27;svc&#x27;, SVC(probability=True)),\n",
       "                               (&#x27;knn&#x27;, KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=3, n_estimators=350, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>knn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(min_samples_split=3,\n",
       "                                                       n_estimators=350,\n",
       "                                                       random_state=42)),\n",
       "                               ('svc', SVC(probability=True)),\n",
       "                               ('knn', KNeighborsClassifier())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Define individual classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=350, random_state=42, min_samples_split=3, min_samples_leaf=1, max_depth=None)\n",
    "clf2 = SVC(probability=True, random_state=42)\n",
    "clf3 = KNeighborsClassifier()\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', clf1),\n",
    "    ('svc', clf2),\n",
    "    ('knn', clf3)\n",
    "], voting='soft')\n",
    "\n",
    "# Fit model\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use voting_clf to make new predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.89, 'f1': 0.8902195608782434, 'precision': 0.8693957115009746, 'recall': 0.9120654396728016, 'auc': 0.8904749898951092, 'confusion_matrix': [[444, 67], [43, 446]]}\n"
     ]
    }
   ],
   "source": [
    "finalPrediction = stack_clf.predict(X_test)\n",
    "\n",
    "print(getMetrics(finalPrediction,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
