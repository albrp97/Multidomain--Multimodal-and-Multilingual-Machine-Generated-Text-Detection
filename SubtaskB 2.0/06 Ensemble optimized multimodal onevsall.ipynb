{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from transformers import AutoConfig, RobertaModel, RobertaForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import pandas as pd,os\n",
    "import torch\n",
    "from statistics import mode\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline, Trainer\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import pickle\n",
    "from transformers import RobertaConfig, RobertaModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoConfig, RobertaModel, RobertaForSequenceClassification\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from typing import Optional, Union, Tuple\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback,AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textstat.textstat import textstatistics\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for sentence-level classification tasks.\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_extra_dims):\n",
    "        super().__init__()\n",
    "        total_dims = config.hidden_size+num_extra_dims\n",
    "        self.dense = nn.Linear(total_dims, total_dims)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.out_proj = nn.Linear(total_dims, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dropout(features)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "class CustomSequenceClassification(RobertaForSequenceClassification):\n",
    "\n",
    "    def __init__(self, config, num_extra_dims):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        # might need to rename this depending on the model\n",
    "        self.roberta =  RobertaModel(config)\n",
    "        self.classifier = ClassificationHead(config, num_extra_dims)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        extra_data: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        # sequence_output will be (batch_size, seq_length, hidden_size)\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        # additional data should be (batch_size, num_extra_dims)\n",
    "        cls_embedding = sequence_output[:, 0, :]\n",
    "\n",
    "        output = torch.cat((cls_embedding, extra_data), dim=-1)\n",
    "\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = nn.MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = nn.CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = nn.BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3000 non-null   object\n",
      " 1   model   3000 non-null   object\n",
      " 2   source  3000 non-null   object\n",
      " 3   label   3000 non-null   int64 \n",
      " 4   id      3000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n",
      "\n",
      "label\n",
      "1    500\n",
      "0    500\n",
      "3    500\n",
      "2    500\n",
      "4    500\n",
      "5    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "chatGPT    500\n",
      "human      500\n",
      "davinci    500\n",
      "cohere     500\n",
      "bloomz     500\n",
      "dolly      500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "source\n",
      "peerread    3000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('datasets/subtaskB_dev.jsonl', lines=True)\n",
    "\n",
    "print(f'Original dataset')\n",
    "print(df.info())\n",
    "\n",
    "print(f'''\\n{df['label'].value_counts()}''')\n",
    "print(f'''\\n{df['model'].value_counts()}''')\n",
    "print(f'''\\n{df['source'].value_counts()}''')\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "test_df=df\n",
    "\n",
    "test_texts = test_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    3000 non-null   object\n",
      " 1   model   3000 non-null   object\n",
      " 2   source  3000 non-null   object\n",
      " 3   label   3000 non-null   int64 \n",
      " 4   id      3000 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n",
      "\n",
      "label\n",
      "1    500\n",
      "0    500\n",
      "3    500\n",
      "2    500\n",
      "4    500\n",
      "5    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "chatGPT    500\n",
      "human      500\n",
      "davinci    500\n",
      "cohere     500\n",
      "bloomz     500\n",
      "dolly      500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "source\n",
      "peerread    3000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing with bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 5017.26 examples/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 8257.45 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 7810.77 examples/s]\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:05<00:00, 64.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with google/electra-base-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 6141.48 examples/s]\n",
      "You're using a ElectraTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with albert-base-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 5480.99 examples/s]\n",
      "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:13<00:00, 27.86it/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:01<00:00, 1506.36 examples/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 27837.32 examples/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:01<00:00, 1552.31 examples/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 29677.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with multimodal-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:15<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with multimodal-extended-roberta-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:15<00:00, 24.98it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL1 = 'bert-base-uncased'\n",
    "MODEL2 = 'roberta-base'\n",
    "MODEL3 = 'distilbert-base-uncased'\n",
    "MODEL4 = 'google/electra-base-discriminator'\n",
    "MODEL5 = 'albert-base-v2'\n",
    "MODEL6 = 'multimodal-roberta-base'\n",
    "MODEL7 = 'multimodal-extended-roberta-base'\n",
    "\n",
    "MODEL_PATH1='SavedModels/optimized-bert-base-uncased-50k'\n",
    "MODEL_PATH2='SavedModels/optimized-roberta-base-30k'\n",
    "MODEL_PATH3='SavedModels/optimized-distilbert-base-uncased-50k'\n",
    "MODEL_PATH4='SavedModels/optimized-electra-base-discriminator-50k'\n",
    "MODEL_PATH5='SavedModels/optimized-albert-base-v2-15k'\n",
    "MODEL_PATH6='SavedModels/optimized-roberta-base-multimodal-70k'\n",
    "MODEL_PATH7='SavedModels/optimized-roberta-base-multimodal-extended-70k'\n",
    "\n",
    "'''Preparing data'''\n",
    "\n",
    "df = pd.read_json('datasets/subtaskB_dev.jsonl', lines=True)\n",
    "\n",
    "print(f'Original dataset')\n",
    "print(df.info())\n",
    "\n",
    "print(f'''\\n{df['label'].value_counts()}''')\n",
    "print(f'''\\n{df['model'].value_counts()}''')\n",
    "print(f'''\\n{df['source'].value_counts()}''')\n",
    "\n",
    "df = df[['text', 'label']]\n",
    "test_df=df\n",
    "\n",
    "test_texts = test_df['text'].tolist()\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "def getPrediction(model_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    id2label = {0: 'human', 1: 'chatGPT', 2: 'cohere', 3: 'davinci', 4: 'bloomz', 5: 'dolly'}\n",
    "    label2id = {'human': 0, 'chatGPT': 1,'cohere': 2, 'davinci': 3, 'bloomz': 4, 'dolly': 5}\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "        )\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    def preprocess_function(examples, **fn_kwargs):\n",
    "        return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n",
    "\n",
    "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        # compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(tokenized_test_dataset)\n",
    "    probs = expit(predictions.predictions)  # Use sigmoid instead of softmax\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "    return preds, probs\n",
    "\n",
    "def getPredictionMultidomain(model_path,num_extra_dims,test_data):\n",
    "    config = RobertaConfig.from_pretrained(model_path)\n",
    "    model = CustomSequenceClassification(config, num_extra_dims)\n",
    "    model.load_state_dict(torch.load(model_path+'/pytorch_model.bin'))\n",
    "    trainer = Trainer(model=model)\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(test_data)\n",
    "    probs = expit(predictions.predictions)  # Use sigmoid instead of softmax\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "    return preds, probs\n",
    "\n",
    "print(f'\\nProcessing with {MODEL1}')\n",
    "labels1,scores1=getPrediction(MODEL_PATH1)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL2}')\n",
    "labels2,scores2=getPrediction(MODEL_PATH2)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL3}')\n",
    "labels3,scores3=getPrediction(MODEL_PATH3)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL4}')\n",
    "labels4,scores4=getPrediction(MODEL_PATH4)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL5}')\n",
    "labels5,scores5=getPrediction(MODEL_PATH5)\n",
    "\n",
    "df_multidomain_extended=pd.read_csv('datasets/features_df_test_extended.csv')\n",
    "\n",
    "reduced_columns=['word_count','avg_sentence_length','avg_word_length','gunning_fog_index','grammatical_errors','text','label']\n",
    "df_multidomain=df_multidomain_extended[reduced_columns]\n",
    "\n",
    "df_multidomain_extraData=df_multidomain.drop(['label'],axis=1)\n",
    "df_multidomain_extraData=df_multidomain_extraData.drop(['text'],axis=1)\n",
    "\n",
    "df_multidomain_extended_extraData=df_multidomain_extended.drop(['label'],axis=1)\n",
    "df_multidomain_extended_extraData=df_multidomain_extended_extraData.drop(['text'],axis=1)\n",
    "\n",
    "ds_test_extended = Dataset.from_dict({\n",
    "        \"text\": df_multidomain_extended['text'].tolist(), \n",
    "        \"extra_data\": df_multidomain_extended_extraData.values.tolist(),\n",
    "        \"labels\": df_multidomain_extended['label'].tolist()\n",
    "    })\n",
    "\n",
    "ds_test = Dataset.from_dict({\n",
    "        \"text\": df_multidomain['text'].tolist(), \n",
    "        \"extra_data\": df_multidomain_extraData.values.tolist(),\n",
    "        \"labels\": df_multidomain['label'].tolist()\n",
    "    })\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "tokenized_ds_test_extended = ds_test_extended.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True))\n",
    "tokenized_ds_test_extended = tokenized_ds_test_extended.map(lambda x: {'extra_data': x['extra_data']})\n",
    "\n",
    "tokenized_ds_test = ds_test.map(lambda x: tokenizer(x[\"text\"], padding='max_length', truncation=True))\n",
    "tokenized_ds_test = tokenized_ds_test.map(lambda x: {'extra_data': x['extra_data']})\n",
    "\n",
    "print(f'\\nProcessing with {MODEL6}')\n",
    "labels6,scores6=getPredictionMultidomain(MODEL_PATH6,5,tokenized_ds_test)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL7}')\n",
    "labels7,scores7=getPredictionMultidomain(MODEL_PATH7,9,tokenized_ds_test_extended)\n",
    "\n",
    "scores1 = [scores1[i][labels1[i]] for i in range(len(labels1))]\n",
    "scores2 = [scores2[i][labels2[i]] for i in range(len(labels2))]\n",
    "scores3 = [scores3[i][labels3[i]] for i in range(len(labels3))]\n",
    "scores4 = [scores4[i][labels4[i]] for i in range(len(labels4))]\n",
    "scores5 = [scores5[i][labels5[i]] for i in range(len(labels5))]\n",
    "scores6 = [scores6[i][labels6[i]] for i in range(len(labels6))]\n",
    "scores7 = [scores7[i][labels7[i]] for i in range(len(labels7))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 6894.42 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 7847.28 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 8445.09 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 35.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 4297.81 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 8171.53 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:11<00:00, 33.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with onevsall-roberta-base label 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 8222.16 examples/s]\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 375/375 [00:10<00:00, 34.22it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL8 = 'onevsall-roberta-base'\n",
    "MODEL_PATH8_0='SavedModels/roberta-base_label0_0k'\n",
    "MODEL_PATH8_1='SavedModels/roberta-base_label1_0k'\n",
    "MODEL_PATH8_2='SavedModels/roberta-base_label2_0k'\n",
    "MODEL_PATH8_3='SavedModels/roberta-base_label3_0k'\n",
    "MODEL_PATH8_4='SavedModels/roberta-base_label4_0k'\n",
    "MODEL_PATH8_5='SavedModels/roberta-base_label5_0k'\n",
    "\n",
    "def getPredictionBinary(model_path):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    id2label = {0: \"not_current_model\", 1: \"current_model\"}\n",
    "    label2id = {\"not_current_model\": 0, \"current_model\": 1}\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    "        )\n",
    "\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    def preprocess_function(examples, **fn_kwargs):\n",
    "        return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n",
    "\n",
    "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    # create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        # compute_metrics=compute_metrics,\n",
    "    )\n",
    "    # get logits from predictions and evaluate results using classification report\n",
    "    predictions = trainer.predict(tokenized_test_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    probs = softmax(predictions.predictions, axis=-1)\n",
    "    label_specific_probs = probs[:, 1]  # This extracts the probability for label 1\n",
    "    \n",
    "    return list(preds),list(label_specific_probs)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 0')\n",
    "labels8_0,scores8_0=getPredictionBinary(MODEL_PATH8_0)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 1')\n",
    "labels8_1,scores8_1=getPredictionBinary(MODEL_PATH8_1)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 2')\n",
    "labels8_2,scores8_2=getPredictionBinary(MODEL_PATH8_2)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 3')\n",
    "labels8_3,scores8_3=getPredictionBinary(MODEL_PATH8_3)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 4')\n",
    "labels8_4,scores8_4=getPredictionBinary(MODEL_PATH8_4)\n",
    "\n",
    "print(f'\\nProcessing with {MODEL8} label 5')\n",
    "labels8_5,scores8_5=getPredictionBinary(MODEL_PATH8_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onevsall = pd.DataFrame({\n",
    "    f'Labels_0': labels8_0,\n",
    "    f'Scores_0': scores8_0,\n",
    "    f'Labels_1': labels8_1,\n",
    "    f'Scores_1': scores8_1,\n",
    "    f'Labels_2': labels8_2,\n",
    "    f'Scores_2': scores8_2,\n",
    "    f'Labels_3': labels8_3,\n",
    "    f'Scores_3': scores8_3,\n",
    "    f'Labels_4': labels8_4,\n",
    "    f'Scores_4': scores8_4,\n",
    "    f'Labels_5': labels8_5,\n",
    "    f'Scores_5': scores8_5,\n",
    "})\n",
    "\n",
    "def process_labels_and_scores(df):\n",
    "    labels8 = []\n",
    "    scores8 = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        labels = [row[f'Labels_{i}'] for i in range(6)]\n",
    "        scores = [row[f'Scores_{i}'] for i in range(6)]\n",
    "\n",
    "        if labels.count(1) == 1:\n",
    "            # Only one label is 1\n",
    "            label_index = labels.index(1)\n",
    "            selected_label = label_index\n",
    "            selected_score = scores[label_index]\n",
    "        elif labels.count(1) > 1:\n",
    "            # Multiple labels are 1, choose the one with the highest score\n",
    "            selected_label = scores.index(max(scores))\n",
    "            selected_score = max(scores)\n",
    "        else:\n",
    "            # All labels are 0, choose the one with the lowest score and invert the score\n",
    "            selected_label = scores.index(min(scores))\n",
    "            selected_score = 1 - min(scores)\n",
    "\n",
    "        labels8.append(selected_label)\n",
    "        scores8.append(selected_score)\n",
    "\n",
    "    return labels8, scores8\n",
    "\n",
    "labels8, scores8 = process_labels_and_scores(df_onevsall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased\n",
      "{'accuracy': 0.6583333333333333, 'f1': 0.6185394311264053, 'precision': 0.6192174884481815, 'recall': 0.6583333333333333}\n",
      "\n",
      "roberta-base\n",
      "{'accuracy': 0.7473333333333333, 'f1': 0.7167924853853949, 'precision': 0.7252336532426344, 'recall': 0.7473333333333333}\n",
      "\n",
      "distilbert-base-uncased\n",
      "{'accuracy': 0.654, 'f1': 0.6295894012802586, 'precision': 0.6580674916276797, 'recall': 0.6539999999999999}\n",
      "\n",
      "google/electra-base-discriminator\n",
      "{'accuracy': 0.684, 'f1': 0.6546814757852748, 'precision': 0.6841279878821579, 'recall': 0.684}\n",
      "\n",
      "albert-base-v2\n",
      "{'accuracy': 0.674, 'f1': 0.654733141514451, 'precision': 0.6594659303977864, 'recall': 0.6739999999999999}\n",
      "\n",
      "multimodal-roberta-base\n",
      "{'accuracy': 0.759, 'f1': 0.7186877887437483, 'precision': 0.7309157154173311, 'recall': 0.759}\n",
      "\n",
      "multimodal-extended-roberta-base\n",
      "{'accuracy': 0.742, 'f1': 0.7095807039739542, 'precision': 0.7254381710357943, 'recall': 0.742}\n",
      "\n",
      "onevsall-roberta-base\n",
      "{'accuracy': 0.732, 'f1': 0.6996097578573203, 'precision': 0.7098975226957621, 'recall': 0.7319999999999999}\n"
     ]
    }
   ],
   "source": [
    "def getMetrics(predicted_labels, true_labels):\n",
    "    # Ensure the labels are numpy arrays\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro', zero_division=0)\n",
    "\n",
    "    # Create a dictionary of metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(MODEL1)\n",
    "print(getMetrics(labels1,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL2)\n",
    "print(getMetrics(labels2,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL3)\n",
    "print(getMetrics(labels3,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL4)\n",
    "print(getMetrics(labels4,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL5)\n",
    "print(getMetrics(labels5,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL6)\n",
    "print(getMetrics(labels6,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL7)\n",
    "print(getMetrics(labels7,test_df['label'].tolist()))\n",
    "print('')\n",
    "print(MODEL8)\n",
    "print(getMetrics(labels8,test_df['label'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                    Non-Null Count  Dtype  \n",
      "---  ------                                    --------------  -----  \n",
      " 0   Labels_bert-base-uncased                  3000 non-null   int64  \n",
      " 1   Scores_bert-base-uncased                  3000 non-null   float32\n",
      " 2   Labels_roberta-base                       3000 non-null   int64  \n",
      " 3   Scores_roberta-base                       3000 non-null   float32\n",
      " 4   Labels_distilbert-base-uncased            3000 non-null   int64  \n",
      " 5   Scores_distilbert-base-uncased            3000 non-null   float32\n",
      " 6   Labels_google/electra-base-discriminator  3000 non-null   int64  \n",
      " 7   Scores_google/electra-base-discriminator  3000 non-null   float32\n",
      " 8   Labels_albert-base-v2                     3000 non-null   int64  \n",
      " 9   Scores_albert-base-v2                     3000 non-null   float32\n",
      " 10  Labels_multimodal-roberta-base            3000 non-null   int64  \n",
      " 11  Scores_multimodal-roberta-base            3000 non-null   float32\n",
      " 12  Labels_multimodal-extended-roberta-base   3000 non-null   int64  \n",
      " 13  Scores_multimodal-extended-roberta-base   3000 non-null   float32\n",
      " 14  Labels_onevsall-roberta-base              3000 non-null   int64  \n",
      " 15  Scores_onevsall-roberta-base              3000 non-null   float64\n",
      "dtypes: float32(7), float64(1), int64(8)\n",
      "memory usage: 293.1 KB\n",
      "Majority Voting: 0.7546666666666667\n",
      "Majority Score Tie Break Voting: 0.7543333333333333\n",
      "Rank Voting: 0.7543333333333333\n",
      "Borda Count Voting: 0.757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models = [MODEL1, MODEL2, MODEL3, MODEL4, MODEL5, MODEL6, MODEL7, MODEL8]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    f'Labels_{MODEL1}': labels1,\n",
    "    f'Scores_{MODEL1}': scores1,\n",
    "    f'Labels_{MODEL2}': labels2,\n",
    "    f'Scores_{MODEL2}': scores2,\n",
    "    f'Labels_{MODEL3}': labels3,\n",
    "    f'Scores_{MODEL3}': scores3,\n",
    "    f'Labels_{MODEL4}': labels4,\n",
    "    f'Scores_{MODEL4}': scores4,\n",
    "    f'Labels_{MODEL5}': labels5,\n",
    "    f'Scores_{MODEL5}': scores5,\n",
    "    f'Labels_{MODEL6}': labels6,\n",
    "    f'Scores_{MODEL6}': scores6,\n",
    "    f'Labels_{MODEL7}': labels7,\n",
    "    f'Scores_{MODEL7}': scores7,\n",
    "    f'Labels_{MODEL8}': labels8,\n",
    "    f'Scores_{MODEL8}': scores8,\n",
    "})\n",
    "\n",
    "labels = test_df['label'].tolist()\n",
    "\n",
    "df.info()\n",
    "\n",
    "def ensemble_methods(df, models):\n",
    "    def majority_voting(df, models):\n",
    "        \"\"\" Majority Voting Ensemble \"\"\"\n",
    "        votes = df[[f'Labels_{m}' for m in models]].mode(axis=1)\n",
    "        return votes[0]\n",
    "\n",
    "    def averaging_ensemble(df, models, threshold=0.5):\n",
    "        \"\"\" Averaging Ensemble with threshold for class labels \"\"\"\n",
    "        avg_scores = df[[f'Scores_{m}' for m in models]].mean(axis=1)\n",
    "        return (avg_scores >= threshold).astype(int)\n",
    "    \n",
    "    def majority_voting_with_tie_breaking(df, models):\n",
    "        \"\"\" Enhanced Majority Voting with Tie-Breaking by Score Mean \"\"\"\n",
    "        votes = df[[f'Labels_{m}' for m in models]].mode(axis=1)\n",
    "        final_labels = []\n",
    "\n",
    "        for row in range(len(df)):\n",
    "            if len(votes.columns) == 1:\n",
    "                final_labels.append(votes.iloc[row, 0])  # No tie\n",
    "            else:\n",
    "                # In case of a tie, break it by mean score\n",
    "                tied_labels = votes.iloc[row]\n",
    "                tied_scores = {}\n",
    "                for label in tied_labels:\n",
    "                    if pd.notna(label):\n",
    "                        tied_scores[label] = df.loc[row, [f'Scores_{m}' for m in models if df.loc[row, f'Labels_{m}'] == label]].mean()\n",
    "                if tied_scores:\n",
    "                    final_labels.append(max(tied_scores, key=tied_scores.get))\n",
    "                else:\n",
    "                    final_labels.append(np.nan)  # Handle case with all NaNs\n",
    "\n",
    "        return final_labels\n",
    "\n",
    "    def mean_score_voting(df, models):\n",
    "        \"\"\" Mean Score Voting with Tie-Breaking based on Vote Count \"\"\"\n",
    "        # Create a DataFrame to hold the mean scores for each label\n",
    "        mean_scores_df = pd.DataFrame()\n",
    "\n",
    "        # Calculate mean scores for each label\n",
    "        for label in set(df[[f'Labels_{m}' for m in models]].values.flatten()):\n",
    "            if pd.notna(label):\n",
    "                mean_scores_df[label] = df[[f'Scores_{m}' for m in models if df[f'Labels_{m}'].iloc[0] == label]].mean(axis=1)\n",
    "\n",
    "        # Determine the label with the highest mean score for each row\n",
    "        max_mean_scores = mean_scores_df.idxmax(axis=1)\n",
    "\n",
    "        final_labels = []\n",
    "        for i, label in enumerate(max_mean_scores):\n",
    "            # Check for ties in mean scores\n",
    "            tied_labels = mean_scores_df.columns[mean_scores_df.iloc[i] == mean_scores_df.iloc[i][label]]\n",
    "            if len(tied_labels) > 1:\n",
    "                # If there's a tie, choose the label with the most votes\n",
    "                vote_counts = df[[f'Labels_{m}' for m in models]].apply(lambda x: (x == tied_labels).sum(), axis=1).iloc[i]\n",
    "                final_labels.append(vote_counts.idxmax())\n",
    "            else:\n",
    "                final_labels.append(label)\n",
    "\n",
    "        return final_labels\n",
    "    \n",
    "    def rank_voting(df, models, top_n=3):\n",
    "        \"\"\" Rank Voting \"\"\"\n",
    "        final_labels = []\n",
    "        for row in range(len(df)):\n",
    "            points = {label: 0 for label in set(df.iloc[row, [df.columns.get_loc(f'Labels_{m}') for m in models]].values) if pd.notna(label)}\n",
    "            for m in models:\n",
    "                label = df.at[row, f'Labels_{m}']\n",
    "                score = df.at[row, f'Scores_{m}']\n",
    "                # Assign points based on score, higher score gets more points\n",
    "                if pd.notna(label):\n",
    "                    points[label] += score\n",
    "            # Sort the labels based on points and take the top label\n",
    "            sorted_labels = sorted(points, key=points.get, reverse=True)\n",
    "            final_labels.append(sorted_labels[0] if sorted_labels else np.nan)\n",
    "        return final_labels\n",
    "    \n",
    "    def borda_count_voting(df, models):\n",
    "        \"\"\" Borda Count Voting \"\"\"\n",
    "        final_labels = []\n",
    "\n",
    "        for row in range(len(df)):\n",
    "            points = {label: 0 for label in set(df[[f'Labels_{m}' for m in models]].iloc[row].values) if pd.notna(label)}\n",
    "\n",
    "            # Collect scores and labels for the current row across all models\n",
    "            scores_labels = [(df.at[row, f'Scores_{m}'], df.at[row, f'Labels_{m}']) for m in models]\n",
    "\n",
    "            # Sort the scores_labels based on scores\n",
    "            scores_labels.sort(reverse=True)\n",
    "\n",
    "            # Assign Borda points based on ranking\n",
    "            for i, (_, label) in enumerate(scores_labels):\n",
    "                if pd.notna(label):\n",
    "                    points[label] += len(models) - i\n",
    "\n",
    "            # Choose the label with maximum points, handle the case with no valid labels\n",
    "            final_labels.append(max(points, key=points.get) if points else np.nan)\n",
    "\n",
    "        return final_labels\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'Majority Voting':majority_voting(df, models),\n",
    "        # 'Average Voting':averaging_ensemble(df, models),\n",
    "        'Majority Score Tie Break Voting': majority_voting_with_tie_breaking(df, models),\n",
    "        # 'Mean Score Voting': mean_score_voting(df, models),\n",
    "        'Rank Voting': rank_voting(df, models),\n",
    "        'Borda Count Voting': borda_count_voting(df, models),\n",
    "    }\n",
    "    \n",
    "    \n",
    "ensemble_results = ensemble_methods(df, models)\n",
    "\n",
    "for voting_method, details in ensemble_results.items():\n",
    "    print(f'''{voting_method}: {getMetrics(details,labels)['accuracy']}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Combinations: 100%|██████████| 8/8 [07:47<00:00, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy Score: 0.768\n",
      "Best Model Combination: ('roberta-base', 'multimodal-roberta-base')\n",
      "Best Voting Method: Majority Voting\n",
      "Best Metrics: {'accuracy': 0.768, 'f1': 0.7266056974216345, 'precision': 0.7286733771545394, 'recall': 0.7679999999999999}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Assuming all_models is a list of your model names\n",
    "all_models = [MODEL1, MODEL2, MODEL3, MODEL4, MODEL5, MODEL6, MODEL7, MODEL8]\n",
    "\n",
    "# This will store the best F1 score, the corresponding model combination, and the voting method\n",
    "best_f1_score = 0\n",
    "best_model_combination = None\n",
    "best_voting_method = None\n",
    "best_metrics=None\n",
    "\n",
    "# Define the voting methods you want to evaluate\n",
    "voting_methods = ['Majority Voting','Majority Score Tie Break Voting','Rank Voting','Borda Count Voting']\n",
    "\n",
    "# Try all possible combinations of the models\n",
    "for r in tqdm(range(1, len(all_models) + 1), desc='Model Combinations'):\n",
    "    for model_combination in itertools.combinations(all_models, r):\n",
    "        # Generate the predictions using the ensemble of the current combination of models\n",
    "        ensemble_results = ensemble_methods(df, model_combination)\n",
    "        \n",
    "        # Evaluate each voting method\n",
    "        for method in voting_methods:\n",
    "            metrics=getMetrics(ensemble_results[method], labels)\n",
    "            f1_score=metrics['accuracy']\n",
    "            \n",
    "            # Update the best combination if the current one is better\n",
    "            if f1_score > best_f1_score:\n",
    "                best_f1_score = f1_score\n",
    "                best_model_combination = model_combination\n",
    "                best_voting_method = method\n",
    "                best_metrics=metrics\n",
    "\n",
    "# Print the best combination, its score, and the voting method\n",
    "print(f\"Best Accuracy Score: {best_f1_score}\")\n",
    "print(f\"Best Model Combination: {best_model_combination}\")\n",
    "print(f\"Best Voting Method: {best_voting_method}\")\n",
    "print(f\"Best Metrics: {best_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Voting: 0.768\n",
      "Majority Score Tie Break Voting: 0.7613333333333333\n",
      "Rank Voting: 0.7613333333333333\n",
      "Borda Count Voting: 0.7613333333333333\n"
     ]
    }
   ],
   "source": [
    "models = [MODEL2, MODEL6]\n",
    "\n",
    "df_reduced = pd.DataFrame({\n",
    "    f'Labels_{MODEL2}': labels2,\n",
    "    f'Scores_{MODEL2}': scores2,\n",
    "    f'Labels_{MODEL6}': labels6,\n",
    "    f'Scores_{MODEL6}': scores6,\n",
    "})\n",
    "\n",
    "ensemble_results = ensemble_methods(df, models)\n",
    "\n",
    "for voting_method, details in ensemble_results.items():\n",
    "    print(f'''{voting_method}: {getMetrics(details,labels)['accuracy']}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1844\n",
       "1        1845\n",
       "2        1846\n",
       "3        1847\n",
       "4        1848\n",
       "        ...  \n",
       "2995    14560\n",
       "2996    14561\n",
       "2997    14562\n",
       "2998    14563\n",
       "2999    14564\n",
       "Name: id, Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_labels=ensemble_results['Majority Voting']\n",
    "df = pd.read_json('datasets/subtaskB_dev.jsonl', lines=True)\n",
    "df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+0klEQVR4nO3de3zP9f//8fvbzmYHwzZzGDnLKYdYFGVMDhF9Sk1mLVRbiHL4lLNaKYeUQ/UtdBDlQ/o4rxGlJYdIREiOO4hsxtfY9vr94bfXt7ehWdveb1636+Xyulx6PV/P1+v1eL2M3Xu+n6/X22YYhiEAAAALK+XoAgAAAByNQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQAACyPQAQUk3Hjxslms5XIudq1a6d27dqZ619//bVsNpsWL15cIufv16+fqlWrViLnKqzMzEw9+eSTCg4Ols1m05AhQxxdkqXcDD8jsDYCEVAA8+bNk81mMxdPT0+FhIQoIiJCM2bM0NmzZ4vkPCdOnNC4ceO0Y8eOIjleUXLm2grilVde0bx58/T000/ro48+0uOPP37NvtWqVVPXrl0LdZ6VK1dq3LhxhazS8bZv3y6bzaaXXnrpmn32798vm82moUOHlmBlQPEiEAE3YMKECfroo480e/ZsPfvss5KkIUOGqGHDhvrpp5/s+r700kv63//93xs6/okTJzR+/PgbDh1r167V2rVrb2ifG3W92t577z3t27evWM//T61bt06tWrXS2LFj1adPHzVr1qxYzrNy5UqNHz++WI5dEpo2baq6devq008/vWafBQsWSJL69OlTUmUBxY5ABNyA+++/X3369FF0dLRGjRqlNWvW6KuvvlJaWpoeeOABuwDk6uoqT0/PYq3n/PnzkiR3d3e5u7sX67mux83NTR4eHg47f0GkpaXJ39/f0WU4jezsbF28ePGq2yIjI/Xbb7/p+++/v+r2Tz/9VHXr1lXTpk2Ls0SgRBGIgH/ovvvu0+jRo3X48GF9/PHHZvvV5hAlJCSoTZs28vf3V5kyZVSnTh39+9//lnR53k+LFi0kSdHR0ebHc/PmzZN0eZ5QgwYNtG3bNt1zzz0qXbq0ue+Vc4jy5OTk6N///reCg4Pl7e2tBx54QEePHrXrU61aNfXr1y/fvn895t/VdrX5IefOndOwYcNUpUoVeXh4qE6dOnrjjTdkGIZdP5vNpri4OH3xxRdq0KCBPDw8dPvtt2v16tVXv+FXSEtLU0xMjIKCguTp6anGjRtr/vz55va8+VSHDh3SihUrzNp///33Ah1fkn7//XfZbDa98cYbevfdd1WjRg15eHioRYsW2rJli9mvX79+mjlzpnldeUue3NxcTZ8+Xbfffrs8PT0VFBSkgQMH6s8//7Q7X25ursaNG6eQkBCVLl1a9957r/bs2XPVP6szZ85oyJAh5n2uWbOmXnvtNeXm5l61/unTp5v179mz56rXGxkZKen/RoL+atu2bdq3b5/ZZ9myZerSpYtCQkLk4eGhGjVqaOLEicrJybnuPc37c/n666+veq/zfrby7N27Vw899JACAgLk6emp5s2b68svv7Trc+nSJY0fP161atWSp6enypUrpzZt2ighIeG6tQCS5OroAoBbweOPP65///vfWrt2rfr373/VPrt371bXrl3VqFEjTZgwQR4eHjpw4IA2bdokSapXr54mTJigMWPGaMCAAbr77rslSXfddZd5jFOnTun+++9X79691adPHwUFBV23rpdfflk2m00jRoxQWlqapk+frvDwcO3YsUNeXl4Fvr6C1PZXhmHogQce0Pr16xUTE6MmTZpozZo1euGFF3T8+HFNmzbNrv+3336rJUuW6JlnnpGPj49mzJihXr166ciRIypXrtw16/rf//1ftWvXTgcOHFBcXJyqV6+uzz//XP369dOZM2c0ePBg1atXTx999JGee+45Va5cWcOGDZMkVahQocDXn2fBggU6e/asBg4cKJvNpsmTJ6tnz5767bff5ObmpoEDB+rEiRNKSEjQRx99lG//gQMHat68eYqOjtagQYN06NAhvf322/rxxx+1adMmubm5SZJGjRqlyZMnq1u3boqIiNDOnTsVERGhCxcu2B3v/Pnzatu2rY4fP66BAweqatWq+u677zRq1CglJydr+vTpdv3nzp2rCxcuaMCAAfLw8FBAQMBVr7N69eq666679Nlnn2natGlycXGxuweS9Nhjj0m6PL+uTJkyGjp0qMqUKaN169ZpzJgxysjI0Ouvv37D9/hqdu/erdatW6tSpUoaOXKkvL299dlnn6lHjx76z3/+owcffFDS5f8JiY+P15NPPqk777xTGRkZ2rp1q7Zv364OHToUSS24hRkA/tbcuXMNScaWLVuu2cfPz8+44447zPWxY8caf/0rNm3aNEOScfLkyWseY8uWLYYkY+7cufm2tW3b1pBkzJkz56rb2rZta66vX7/ekGRUqlTJyMjIMNs/++wzQ5Lx5ptvmm2hoaFGVFTU3x7zerVFRUUZoaGh5voXX3xhSDImTZpk1++hhx4ybDabceDAAbNNkuHu7m7XtnPnTkOS8dZbb+U7119Nnz7dkGR8/PHHZtvFixeNsLAwo0yZMnbXHhoaanTp0uW6x7tW30OHDhmSjHLlyhmnT58225ctW2ZIMv773/+abbGxscbV/mn95ptvDEnGJ598Yte+evVqu/aUlBTD1dXV6NGjh12/cePGGZLs/qwmTpxoeHt7G7/++qtd35EjRxouLi7GkSNH7Or39fU10tLSCnQPZs6caUgy1qxZY7bl5OQYlSpVMsLCwsy28+fP59t34MCBRunSpY0LFy6YbVf+jOT9jK5fv95u37xa//pz1r59e6Nhw4Z2x8vNzTXuuusuo1atWmZb48aNC/xnDFyJj8yAIlKmTJnrPm2WN39l2bJldh9n3AgPDw9FR0cXuH/fvn3l4+Njrj/00EOqWLGiVq5cWajzF9TKlSvl4uKiQYMG2bUPGzZMhmFo1apVdu3h4eGqUaOGud6oUSP5+vrqt99++9vzBAcH69FHHzXb3NzcNGjQIGVmZmrDhg1FcDX/55FHHlHZsmXN9byRsr+rU5I+//xz+fn5qUOHDvrjjz/MpVmzZipTpozWr18vSUpMTFR2draeeeYZu/3zJvFfecy7775bZcuWtTtmeHi4cnJytHHjRrv+vXr1KvDI2COPPCI3Nze7j802bNig48ePmx+XSbIbaTx79qz++OMP3X333Tp//rz27t1boHNdz+nTp7Vu3To9/PDD5vH/+OMPnTp1ShEREdq/f7+OHz8u6fLfsd27d2v//v3/+LywHgIRUEQyMzPtwseVHnnkEbVu3VpPPvmkgoKC1Lt3b3322Wc3FI4qVap0Q5Ona9WqZbdus9lUs2bNG5o/UxiHDx9WSEhIvvtRr149c/tfVa1aNd8xypYtm29uzdXOU6tWLZUqZf9P2bXO809dWWdeOPq7OqXLj6qnp6crMDBQFSpUsFsyMzOVlpZmV3PNmjXt9g8ICLALY3nHXL16db7jhYeHS5J5zDzVq1cv8LWWK1dOERERWrp0qflR3YIFC+Tq6qqHH37Y7Ld79249+OCD8vPzk6+vrypUqGA+fZaenl7g813LgQMHZBiGRo8ene86x44dK+n/rnPChAk6c+aMateurYYNG+qFF17I9/QncC3MIQKKwLFjx5Senp7vl9hfeXl5aePGjVq/fr1WrFih1atXa9GiRbrvvvu0du1au3ka1ztGUbvWyyNzcnIKVFNRuNZ5jCsmYDvaP6kzNzdXgYGB+uSTT666vTBzmnJzc9WhQwcNHz78qttr165tt36jPz99+vTR8uXLtXz5cj3wwAP6z3/+o44dO5q1njlzRm3btpWvr68mTJigGjVqyNPTU9u3b9eIESOuG/av93P3V3nHeP755xUREXHVffL+3t1zzz06ePCgli1bprVr1+p//ud/NG3aNM2ZM0dPPvnkDV07rIdABBSBvAm01/oHO0+pUqXUvn17tW/fXlOnTtUrr7yiF198UevXr1d4eHiRv9n6yo8ODMPQgQMH1KhRI7OtbNmyOnPmTL59Dx8+rNtuu81cv5HaQkND9dVXX+ns2bN2o0R5H6GEhoYW+Fh/d56ffvpJubm5dqNERX2eG3Gt+1SjRg199dVXat269XWDSV7NBw4csBvROXXqVL6RqBo1aigzM9McESpqDzzwgHx8fLRgwQK5ubnpzz//tPu47Ouvv9apU6e0ZMkS3XPPPWb7oUOH/vbYeaNdV/7sXTmql/cz6ObmVqDrDAgIUHR0tKKjo5WZmal77rlH48aNIxDhb/GRGfAPrVu3ThMnTlT16tXtfllc6fTp0/namjRpIknKysqSJHl7e0vK/0uisD788EO7eU2LFy9WcnKy7r//frOtRo0a+v777+3eSbN8+fJ8j+ffSG2dO3dWTk6O3n77bbv2adOmyWaz2Z3/n+jcubNSUlK0aNEisy07O1tvvfWWypQpo7Zt2xbJeW7Ete7Tww8/rJycHE2cODHfPtnZ2Wb/9u3by9XVVbNnz7brc+W9zDtmUlKS1qxZk2/bmTNnlJ2dXciruMzLy0sPPvigVq5cqdmzZ8vb21vdu3c3t+eNmP11hOzixYuaNWvW3x47NDRULi4u+eY5XblvYGCg2rVrp3feeUfJycn5jnPy5Enzv0+dOmW3rUyZMqpZs6b59wu4HkaIgBuwatUq7d27V9nZ2UpNTdW6deuUkJCg0NBQffnll9d9EeOECRO0ceNGdenSRaGhoUpLS9OsWbNUuXJltWnTRtLlcOLv7685c+bIx8dH3t7eatmy5Q3N/firgIAAtWnTRtHR0UpNTdX06dNVs2ZNu1cDPPnkk1q8eLE6deqkhx9+WAcPHtTHH39sN8n5Rmvr1q2b7r33Xr344ov6/fff1bhxY61du1bLli3TkCFD8h27sAYMGKB33nlH/fr107Zt21StWjUtXrxYmzZt0vTp0687p6u45L0Be9CgQYqIiJCLi4t69+6ttm3bauDAgYqPj9eOHTvUsWNHubm5af/+/fr888/15ptv6qGHHlJQUJAGDx6sKVOm6IEHHlCnTp20c+dOrVq1SuXLl7cbgXrhhRf05ZdfqmvXrurXr5+aNWumc+fOadeuXVq8eLF+//13lS9f/h9dT58+ffThhx9qzZo1ioyMNAOfdPm1C2XLllVUVJQGDRokm82mjz76qEAfIfr5+elf//qX3nrrLdlsNtWoUUPLly/PN+9JkmbOnKk2bdqoYcOG6t+/v2677TalpqYqKSlJx44d086dOyVJ9evXV7t27dSsWTMFBARo69atWrx4seLi4v7RPYBFOPAJN+CmkffYfd7i7u5uBAcHGx06dDDefPNNu8e781z52H1iYqLRvXt3IyQkxHB3dzdCQkKMRx99NN8j08uWLTPq169vuLq62j1+3LZtW+P222+/an3Xeuz+008/NUaNGmUEBgYaXl5eRpcuXYzDhw/n23/KlClGpUqVDA8PD6N169bG1q1b8x3zerVd+Ui1YRjG2bNnjeeee84ICQkx3NzcjFq1ahmvv/66kZuba9dPkhEbG5uvpmu9DuBKqampRnR0tFG+fHnD3d3daNiw4VVfDVAUj92//vrr+fpKMsaOHWuuZ2dnG88++6xRoUIFw2az5XsE/9133zWaNWtmeHl5GT4+PkbDhg2N4cOHGydOnLA7xujRo43g4GDDy8vLuO+++4xffvnFKFeunPHUU0/ZHe/s2bPGqFGjjJo1axru7u5G+fLljbvuust44403jIsXL/5t/X8nOzvbqFixoiHJWLlyZb7tmzZtMlq1amV4eXkZISEhxvDhw401a9bke6T+aj8jJ0+eNHr16mWULl3aKFu2rDFw4EDj559/vurrHQ4ePGj07dvXCA4ONtzc3IxKlSoZXbt2NRYvXmz2mTRpknHnnXca/v7+hpeXl1G3bl3j5ZdfNu8DcD02w3CyWYsAgHzOnDmjsmXLatKkSXrxxRcdXQ5wy2EOEQA4mat9KXDeW6ev9hUtAP455hABgJNZtGiR5s2bp86dO6tMmTL69ttv9emnn6pjx45q3bq1o8sDbkkEIgBwMo0aNZKrq6smT56sjIwMc6L1pEmTHF0acMtiDhEAALA85hABAADLIxABAADLYw5RAeTm5urEiRPy8fEp8q9WAAAAxcMwDJ09e1YhISH5vgT6ap0dZsOGDUbXrl3Nl34tXbrUbntubq75cjJPT0+jffv2+V5id+rUKeOxxx4zfHx8DD8/P+OJJ54wzp49a9dn586dRps2bQwPDw+jcuXKxmuvvXZDdR49etTupXwsLCwsLCwsN89y9OjRv/1d79ARonPnzqlx48Z64okn1LNnz3zbJ0+erBkzZmj+/PmqXr26Ro8erYiICO3Zs8f8ioTIyEglJycrISFBly5dUnR0tAYMGKAFCxZIkjIyMtSxY0eFh4drzpw52rVrl5544gn5+/trwIABBaoz7/X/R48ela+vbxFdPQAAKE4ZGRmqUqVKwb7G54aGSoqRZD9ClJubawQHB9u9av7MmTOGh4eH8emnnxqGYRh79uwxJBlbtmwx+6xatcqw2WzG8ePHDcMwjFmzZhlly5Y1srKyzD4jRoww6tSpU+Da0tPTDUlGenp6YS8PAACUsBv5/e20k6oPHTqklJQUhYeHm21+fn5q2bKlkpKSJElJSUny9/dX8+bNzT7h4eEqVaqUNm/ebPa555575O7ubvaJiIjQvn379Oeff1713FlZWcrIyLBbAADArctpA1FKSookKSgoyK49KCjI3JaSkqLAwEC77a6urgoICLDrc7Vj/PUcV4qPj5efn5+5VKlS5Z9fEAAAcFpOG4gcadSoUUpPTzeXo0ePOrokAABQjJw2EAUHB0uSUlNT7dpTU1PNbcHBwUpLS7Pbnp2drdOnT9v1udox/nqOK3l4eMjX19duAQAAty6nDUTVq1dXcHCwEhMTzbaMjAxt3rxZYWFhkqSwsDCdOXNG27ZtM/usW7dOubm5atmypdln48aNunTpktknISFBderUUdmyZUvoagAAgDNzaCDKzMzUjh07tGPHDkmXJ1Lv2LFDR44ckc1m05AhQzRp0iR9+eWX2rVrl/r27auQkBD16NFDklSvXj116tRJ/fv31w8//KBNmzYpLi5OvXv3VkhIiCTpsccek7u7u2JiYrR7924tWrRIb775poYOHeqgqwYAAE6nBJ56u6b169df9QVKUVFRhmH834sZg4KCDA8PD6N9+/bGvn377I5x6tQp49FHHzXKlClj+Pr6GtHR0dd9MWOlSpWMV1999Ybq5LF7AABuPjfy+5tvuy+AjIwM+fn5KT09nflEAADcJG7k97fTziECAAAoKQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgea6OLgBA8ag2coWjS7hp/P5qF0eXAMDBGCECAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACWRyACAACW59SBKCcnR6NHj1b16tXl5eWlGjVqaOLEiTIMw+xjGIbGjBmjihUrysvLS+Hh4dq/f7/dcU6fPq3IyEj5+vrK399fMTExyszMLOnLAQAATsqpA9Frr72m2bNn6+2339Yvv/yi1157TZMnT9Zbb71l9pk8ebJmzJihOXPmaPPmzfL29lZERIQuXLhg9omMjNTu3buVkJCg5cuXa+PGjRowYIAjLgkAADghm/HX4RYn07VrVwUFBen9998323r16iUvLy99/PHHMgxDISEhGjZsmJ5//nlJUnp6uoKCgjRv3jz17t1bv/zyi+rXr68tW7aoefPmkqTVq1erc+fOOnbsmEJCQv62joyMDPn5+Sk9PV2+vr7Fc7FAEas2coWjS7hp/P5qF0eXAKAY3Mjvb6ceIbrrrruUmJioX3/9VZK0c+dOffvtt7r//vslSYcOHVJKSorCw8PNffz8/NSyZUslJSVJkpKSkuTv72+GIUkKDw9XqVKltHnz5queNysrSxkZGXYLAAC4dbk6uoDrGTlypDIyMlS3bl25uLgoJydHL7/8siIjIyVJKSkpkqSgoCC7/YKCgsxtKSkpCgwMtNvu6uqqgIAAs8+V4uPjNX78+KK+HAAA4KSceoTos88+0yeffKIFCxZo+/btmj9/vt544w3Nnz+/WM87atQopaenm8vRo0eL9XwAAMCxnHqE6IUXXtDIkSPVu3dvSVLDhg11+PBhxcfHKyoqSsHBwZKk1NRUVaxY0dwvNTVVTZo0kSQFBwcrLS3N7rjZ2dk6ffq0uf+VPDw85OHhUQxXBAAAnJFTjxCdP39epUrZl+ji4qLc3FxJUvXq1RUcHKzExERze0ZGhjZv3qywsDBJUlhYmM6cOaNt27aZfdatW6fc3Fy1bNmyBK4CAAA4O6ceIerWrZtefvllVa1aVbfffrt+/PFHTZ06VU888YQkyWazaciQIZo0aZJq1aql6tWra/To0QoJCVGPHj0kSfXq1VOnTp3Uv39/zZkzR5cuXVJcXJx69+5doCfMAADArc+pA9Fbb72l0aNH65lnnlFaWppCQkI0cOBAjRkzxuwzfPhwnTt3TgMGDNCZM2fUpk0brV69Wp6enmafTz75RHFxcWrfvr1KlSqlXr16acaMGY64JAAA4ISc+j1EzoL3EOFmxHuICo73EAG3plvmPUQAAAAlgUAEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsz+kD0fHjx9WnTx+VK1dOXl5eatiwobZu3WpuNwxDY8aMUcWKFeXl5aXw8HDt37/f7hinT59WZGSkfH195e/vr5iYGGVmZpb0pQAAACfl1IHozz//VOvWreXm5qZVq1Zpz549mjJlisqWLWv2mTx5smbMmKE5c+Zo8+bN8vb2VkREhC5cuGD2iYyM1O7du5WQkKDly5dr48aNGjBggCMuCQAAOCGbYRiGo4u4lpEjR2rTpk365ptvrrrdMAyFhIRo2LBhev755yVJ6enpCgoK0rx589S7d2/98ssvql+/vrZs2aLmzZtLklavXq3OnTvr2LFjCgkJ+ds6MjIy5Ofnp/T0dPn6+hbdBQLFqNrIFY4u4abx+6tdHF0CgGJwI7+/nXqE6Msvv1Tz5s31r3/9S4GBgbrjjjv03nvvmdsPHTqklJQUhYeHm21+fn5q2bKlkpKSJElJSUny9/c3w5AkhYeHq1SpUtq8efNVz5uVlaWMjAy7BQAA3LqcOhD99ttvmj17tmrVqqU1a9bo6aef1qBBgzR//nxJUkpKiiQpKCjIbr+goCBzW0pKigIDA+22u7q6KiAgwOxzpfj4ePn5+ZlLlSpVivrSAACAE3HqQJSbm6umTZvqlVde0R133KEBAwaof//+mjNnTrGed9SoUUpPTzeXo0ePFuv5AACAYxUqEP32229FXcdVVaxYUfXr17drq1evno4cOSJJCg4OliSlpqba9UlNTTW3BQcHKy0tzW57dna2Tp8+bfa5koeHh3x9fe0WAABw6ypUIKpZs6buvfdeffzxx3ZPcxW11q1ba9++fXZtv/76q0JDQyVJ1atXV3BwsBITE83tGRkZ2rx5s8LCwiRJYWFhOnPmjLZt22b2WbdunXJzc9WyZctiqx0AANw8ChWItm/frkaNGmno0KEKDg7WwIED9cMPPxR1bXruuef0/fff65VXXtGBAwe0YMECvfvuu4qNjZUk2Ww2DRkyRJMmTdKXX36pXbt2qW/fvgoJCVGPHj0kXR5R6tSpk/r3768ffvhBmzZtUlxcnHr37l2gJ8wAAMCtr1CBqEmTJnrzzTd14sQJffDBB0pOTlabNm3UoEEDTZ06VSdPniyS4lq0aKGlS5fq008/VYMGDTRx4kRNnz5dkZGRZp/hw4fr2Wef1YABA9SiRQtlZmZq9erV8vT0NPt88sknqlu3rtq3b6/OnTurTZs2evfdd4ukRgAAcPMrkvcQZWVladasWRo1apQuXrwod3d3Pfzww3rttddUsWLFoqjToXgPEW5GvIeo4HgPEXBrKrH3EG3dulXPPPOMKlasqKlTp+r555/XwYMHlZCQoBMnTqh79+7/5PAAAAAlwrUwO02dOlVz587Vvn371LlzZ3344Yfq3LmzSpW6nK+qV6+uefPmqVq1akVZKwAAQLEoVCCaPXu2nnjiCfXr1++aH4kFBgbq/fff/0fFAQAAlIRCBaIrv03+atzd3RUVFVWYwwMAAJSoQs0hmjt3rj7//PN87Z9//rn5tRoAAAA3i0KNEMXHx+udd97J1x4YGKgBAwYwMgQAtzCeYCw4nmC8eRRqhOjIkSOqXr16vvbQ0FDzazUAAABuFoUKRIGBgfrpp5/yte/cuVPlypX7x0UBAACUpEIFokcffVSDBg3S+vXrlZOTo5ycHK1bt06DBw9W7969i7pGAACAYlWoOUQTJ07U77//rvbt28vV9fIhcnNz1bdvX73yyitFWiAAAEBxK1Qgcnd316JFizRx4kTt3LlTXl5eatiwofkt9AAAADeTQgWiPLVr11bt2rWLqhYAAACHKFQgysnJ0bx585SYmKi0tDTl5ubabV+3bl2RFAcAAFASChWIBg8erHnz5qlLly5q0KCBbDZbUdcFAABQYgoViBYuXKjPPvtMnTt3Lup6AAAASlyhHrt3d3dXzZo1i7oWAAAAhyhUIBo2bJjefPNNGYZR1PUAAACUuEJ9ZPbtt99q/fr1WrVqlW6//Xa5ubnZbV+yZEmRFAcAAFASChWI/P399eCDDxZ1LQAAAA5RqEA0d+7coq4DKBC+ZRsAUBwKNYdIkrKzs/XVV1/pnXfe0dmzZyVJJ06cUGZmZpEVBwAAUBIKNUJ0+PBhderUSUeOHFFWVpY6dOggHx8fvfbaa8rKytKcOXOKuk4AAIBiU6gRosGDB6t58+b6888/5eXlZbY/+OCDSkxMLLLiAAAASkKhRoi++eYbfffdd3J3d7drr1atmo4fP14khQEAAJSUQo0Q5ebmKicnJ1/7sWPH5OPj84+LAgAAKEmFCkQdO3bU9OnTzXWbzabMzEyNHTuWr/MAAAA3nUJ9ZDZlyhRFRESofv36unDhgh577DHt379f5cuX16efflrUNQIAABSrQgWiypUra+fOnVq4cKF++uknZWZmKiYmRpGRkXaTrAEAAG4GhQpEkuTq6qo+ffoUZS0AANxSeJlswf3+aheHnr9QgejDDz+87va+ffsWqhgAAABHKFQgGjx4sN36pUuXdP78ebm7u6t06dIEIgAAcFMp1FNmf/75p92SmZmpffv2qU2bNkyqBgAAN51Cf5fZlWrVqqVXX3013+gRAACAsyuyQCRdnmh94sSJojwkAABAsSvUHKIvv/zSbt0wDCUnJ+vtt99W69ati6QwAACAklKoQNSjRw+7dZvNpgoVKui+++7TlClTiqIuAACAElOoQJSbm1vUdQAAADhMkc4hAgAAuBkVaoRo6NChBe47derUwpwCAACgxBQqEP3444/68ccfdenSJdWpU0eS9Ouvv8rFxUVNmzY1+9lstqKpEgAAoBgVKhB169ZNPj4+mj9/vsqWLSvp8ssao6Ojdffdd2vYsGFFWiQAAEBxKtQcoilTpig+Pt4MQ5JUtmxZTZo0iafMAADATadQgSgjI0MnT57M137y5EmdPXv2HxcFAABQkgoViB588EFFR0dryZIlOnbsmI4dO6b//Oc/iomJUc+ePYu6RgAAgGJVqDlEc+bM0fPPP6/HHntMly5dunwgV1fFxMTo9ddfL9ICAQAAiluhAlHp0qU1a9Ysvf766zp48KAkqUaNGvL29i7S4gAAAErCP3oxY3JyspKTk1WrVi15e3vLMIyiqgsAAKDEFCoQnTp1Su3bt1ft2rXVuXNnJScnS5JiYmJ45B4AANx0ChWInnvuObm5uenIkSMqXbq02f7II49o9erVRVYcAABASSjUHKK1a9dqzZo1qly5sl17rVq1dPjw4SIpDAAAoKQUaoTo3LlzdiNDeU6fPi0PD49/XBQAAEBJKlQguvvuu/Xhhx+a6zabTbm5uZo8ebLuvffeIisOAACgJBTqI7PJkyerffv22rp1qy5evKjhw4dr9+7dOn36tDZt2lTUNQIAABSrQo0QNWjQQL/++qvatGmj7t2769y5c+rZs6d+/PFH1ahRo6hrBAAAKFY3PEJ06dIlderUSXPmzNGLL75YHDUBAACUqBseIXJzc9NPP/1UHLUAAAA4RKE+MuvTp4/ef//9oq4FAADAIQo1qTo7O1sffPCBvvrqKzVr1izfd5hNnTq1SIoDAAAoCTcUiH777TdVq1ZNP//8s5o2bSpJ+vXXX+362Gy2oqsOAACgBNxQIKpVq5aSk5O1fv16SZe/qmPGjBkKCgoqluIAAABKwg3NIbry2+xXrVqlc+fOFWlBAAAAJa1Qk6rzXBmQAAAAbkY3FIhsNlu+OUIlOWfo1Vdflc1m05AhQ8y2CxcuKDY2VuXKlVOZMmXUq1cvpaam2u135MgRdenSRaVLl1ZgYKBeeOEFZWdnl1jdAADAud3QHCLDMNSvXz/zC1wvXLigp556Kt9TZkuWLCm6Cv+/LVu26J133lGjRo3s2p977jmtWLFCn3/+ufz8/BQXF6eePXuaXyGSk5OjLl26KDg4WN99952Sk5PVt29fubm56ZVXXinyOgEAwM3nhgJRVFSU3XqfPn2KtJhryczMVGRkpN577z1NmjTJbE9PT9f777+vBQsW6L777pMkzZ07V/Xq1dP333+vVq1aae3atdqzZ4+++uorBQUFqUmTJpo4caJGjBihcePGyd3dvUSuAQAAOK8bCkRz584trjquKzY2Vl26dFF4eLhdINq2bZsuXbqk8PBws61u3bqqWrWqkpKS1KpVKyUlJalhw4Z2T8JFRETo6aef1u7du3XHHXfkO19WVpaysrLM9YyMjGK6MgAA4AwK9WLGkrRw4UJt375dW7ZsybctJSVF7u7u8vf3t2sPCgpSSkqK2efK1wLkref1uVJ8fLzGjx9fBNUDAICbwT96yqy4HT16VIMHD9Ynn3wiT0/PEjvvqFGjlJ6ebi5Hjx4tsXMDAICS59SBaNu2bUpLS1PTpk3l6uoqV1dXbdiwQTNmzJCrq6uCgoJ08eJFnTlzxm6/1NRUBQcHS5KCg4PzPXWWt57X50oeHh7y9fW1WwAAwK3LqQNR+/bttWvXLu3YscNcmjdvrsjISPO/3dzclJiYaO6zb98+HTlyRGFhYZKksLAw7dq1S2lpaWafhIQE+fr6qn79+iV+TQAAwPk49RwiHx8fNWjQwK7N29tb5cqVM9tjYmI0dOhQBQQEyNfXV88++6zCwsLUqlUrSVLHjh1Vv359Pf7445o8ebJSUlL00ksvKTY21nx9AAAAsDanDkQFMW3aNJUqVUq9evVSVlaWIiIiNGvWLHO7i4uLli9frqefflphYWHy9vZWVFSUJkyY4MCqAQCAM7npAtHXX39tt+7p6amZM2dq5syZ19wnNDRUK1euLObKAADAzcqp5xABAACUBAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPAIRAACwPFdHFwCp2sgVji4BAABLY4QIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYnlMHovj4eLVo0UI+Pj4KDAxUjx49tG/fPrs+Fy5cUGxsrMqVK6cyZcqoV69eSk1Ntetz5MgRdenSRaVLl1ZgYKBeeOEFZWdnl+SlAAAAJ+bUgWjDhg2KjY3V999/r4SEBF26dEkdO3bUuXPnzD7PPfec/vvf/+rzzz/Xhg0bdOLECfXs2dPcnpOToy5duujixYv67rvvNH/+fM2bN09jxoxxxCUBAAAnZDMMw3B0EQV18uRJBQYGasOGDbrnnnuUnp6uChUqaMGCBXrooYckSXv37lW9evWUlJSkVq1aadWqVeratatOnDihoKAgSdKcOXM0YsQInTx5Uu7u7n973oyMDPn5+Sk9PV2+vr5Ffl3VRq4o8mMCKLjfX+3i6BJuKvybheJQHH8Pb+T3t1OPEF0pPT1dkhQQECBJ2rZtmy5duqTw8HCzT926dVW1alUlJSVJkpKSktSwYUMzDElSRESEMjIytHv37hKsHgAAOCtXRxdQULm5uRoyZIhat26tBg0aSJJSUlLk7u4uf39/u75BQUFKSUkx+/w1DOVtz9t2NVlZWcrKyjLXMzIyiuoyAACAE7ppRohiY2P1888/a+HChcV+rvj4ePn5+ZlLlSpViv2cAADAcW6KQBQXF6fly5dr/fr1qly5stkeHBysixcv6syZM3b9U1NTFRwcbPa58qmzvPW8PlcaNWqU0tPTzeXo0aNFeDUAAMDZOHUgMgxDcXFxWrp0qdatW6fq1avbbW/WrJnc3NyUmJhotu3bt09HjhxRWFiYJCksLEy7du1SWlqa2SchIUG+vr6qX7/+Vc/r4eEhX19fuwUAANy6nHoOUWxsrBYsWKBly5bJx8fHnPPj5+cnLy8v+fn5KSYmRkOHDlVAQIB8fX317LPPKiwsTK1atZIkdezYUfXr19fjjz+uyZMnKyUlRS+99JJiY2Pl4eHhyMsDAABOwqkD0ezZsyVJ7dq1s2ufO3eu+vXrJ0maNm2aSpUqpV69eikrK0sRERGaNWuW2dfFxUXLly/X008/rbCwMHl7eysqKkoTJkwoqcsAAABOzqkDUUFekeTp6amZM2dq5syZ1+wTGhqqlStXFmVpAADgFuLUc4gAAABKAoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYnqujCwAAR6s2coWjSwDgYIwQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAyyMQAQAAy7NUIJo5c6aqVasmT09PtWzZUj/88IOjSwIAAE7AMoFo0aJFGjp0qMaOHavt27ercePGioiIUFpamqNLAwAADmaZQDR16lT1799f0dHRql+/vubMmaPSpUvrgw8+cHRpAADAwSwRiC5evKht27YpPDzcbCtVqpTCw8OVlJTkwMoAAIAzcHV0ASXhjz/+UE5OjoKCguzag4KCtHfv3nz9s7KylJWVZa6np6dLkjIyMoqlvtys88VyXAAAbhbF8Ts275iGYfxtX0sEohsVHx+v8ePH52uvUqWKA6oBAODW5ze9+I599uxZ+fn5XbePJQJR+fLl5eLiotTUVLv21NRUBQcH5+s/atQoDR061FzPzc3V6dOnVa5cOdlstmKv1xlkZGSoSpUqOnr0qHx9fR1djlPjXhUc96rguFcFx70qOKvdK8MwdPbsWYWEhPxtX0sEInd3dzVr1kyJiYnq0aOHpMshJzExUXFxcfn6e3h4yMPDw67N39+/BCp1Pr6+vpb4S1MUuFcFx70qOO5VwXGvCs5K9+rvRobyWCIQSdLQoUMVFRWl5s2b684779T06dN17tw5RUdHO7o0AADgYJYJRI888ohOnjypMWPGKCUlRU2aNNHq1avzTbQGAADWY5lAJElxcXFX/YgM+Xl4eGjs2LH5PjpEftyrguNeFRz3quC4VwXHvbo2m1GQZ9EAAABuYZZ4MSMAAMD1EIgAAIDlEYgAAIDlEYgAAIDlEYiQz8yZM1WtWjV5enqqZcuW+uGHHxxdklPauHGjunXrppCQENlsNn3xxReOLskpxcfHq0WLFvLx8VFgYKB69Oihffv2ObospzV79mw1atTIfHFeWFiYVq1a5eiynN6rr74qm82mIUOGOLoUpzRu3DjZbDa7pW7duo4uy6kQiGBn0aJFGjp0qMaOHavt27ercePGioiIUFpamqNLczrnzp1T48aNNXPmTEeX4tQ2bNig2NhYff/990pISNClS5fUsWNHnTt3ztGlOaXKlSvr1Vdf1bZt27R161bdd9996t69u3bv3u3o0pzWli1b9M4776hRo0aOLsWp3X777UpOTjaXb7/91tElORUeu4edli1bqkWLFnr77bclXf6KkypVqujZZ5/VyJEjHVyd87LZbFq6dKn51TC4tpMnTyowMFAbNmzQPffc4+hybgoBAQF6/fXXFRMT4+hSnE5mZqaaNm2qWbNmadKkSWrSpImmT5/u6LKczrhx4/TFF19ox44dji7FaTFCBNPFixe1bds2hYeHm22lSpVSeHi4kpKSHFgZbiXp6emSLv+Sx/Xl5ORo4cKFOnfunMLCwhxdjlOKjY1Vly5d7P7dwtXt379fISEhuu222xQZGakjR444uiSnYqk3VeP6/vjjD+Xk5OT7OpOgoCDt3bvXQVXhVpKbm6shQ4aodevWatCggaPLcVq7du1SWFiYLly4oDJlymjp0qWqX7++o8tyOgsXLtT27du1ZcsWR5fi9Fq2bKl58+apTp06Sk5O1vjx43X33Xfr559/lo+Pj6PLcwoEIgAlJjY2Vj///DNzF/5GnTp1tGPHDqWnp2vx4sWKiorShg0bCEV/cfToUQ0ePFgJCQny9PR0dDlO7/777zf/u1GjRmrZsqVCQ0P12Wef8VHs/0cggql8+fJycXFRamqqXXtqaqqCg4MdVBVuFXFxcVq+fLk2btyoypUrO7ocp+bu7q6aNWtKkpo1a6YtW7bozTff1DvvvOPgypzHtm3blJaWpqZNm5ptOTk52rhxo95++21lZWXJxcXFgRU6N39/f9WuXVsHDhxwdClOgzlEMLm7u6tZs2ZKTEw023Jzc5WYmMj8BRSaYRiKi4vT0qVLtW7dOlWvXt3RJd10cnNzlZWV5egynEr79u21a9cu7dixw1yaN2+uyMhI7dixgzD0NzIzM3Xw4EFVrFjR0aU4DUaIYGfo0KGKiopS8+bNdeedd2r69Ok6d+6coqOjHV2a08nMzLT7v6tDhw5px44dCggIUNWqVR1YmXOJjY3VggULtGzZMvn4+CglJUWS5OfnJy8vLwdX53xGjRql+++/X1WrVtXZs2e1YMECff3111qzZo2jS3MqPj4++eaheXt7q1y5csxPu4rnn39e3bp1U2hoqE6cOKGxY8fKxcVFjz76qKNLcxoEIth55JFHdPLkSY0ZM0YpKSlq0qSJVq9enW+iNaStW7fq3nvvNdeHDh0qSYqKitK8efMcVJXzmT17tiSpXbt2du1z585Vv379Sr4gJ5eWlqa+ffsqOTlZfn5+atSokdasWaMOHTo4ujTcxI4dO6ZHH31Up06dUoUKFdSmTRt9//33qlChgqNLcxq8hwgAAFgec4gAAIDlEYgAAIDlEYgAAIDlEYgAAIDlEYgAAIDlEYgAAIDlEYgAAIDlEYgAoBiNGzdOTZo0cXQZAP4GgQjAP9avXz/16NHjhvax2Wz64osviqWeojBlyhSVLVtWFy5cyLft/Pnz8vX11YwZMxxQGYDiQCACYHkXL17M1/b444/r3LlzWrJkSb5tixcv1sWLF9WnT5+SKA9ACSAQAShy7dq106BBgzR8+HAFBAQoODhY48aNM7dXq1ZNkvTggw/KZrOZ65K0bNkyNW3aVJ6enrrttts0fvx4ZWdnm9v37t2rNm3ayNPTU/Xr19dXX32Vb7Tp6NGjevjhh+Xv76+AgAB1795dv//+u7k9b0Tr5ZdfVkhIiOrUqZPvGgIDA9WtWzd98MEH+bZ98MEH6tGjhwICAjRixAjVrl1bpUuX1m233abRo0fr0qVL1703Q4YMsWvr0aOH3fe6ZWVl6fnnn1elSpXk7e2tli1b6uuvvza3Hz58WN26dVPZsmXl7e2t22+/XStXrrzmOQH8Pb7cFUCxmD9/voYOHarNmzcrKSlJ/fr1U+vWrdWhQwdt2bJFgYGBmjt3rjp16iQXFxdJ0jfffKO+fftqxowZuvvuu3Xw4EENGDBAkjR27Fjl5OSoR48eqlq1qjZv3qyzZ89q2LBhdue9dOmSIiIiFBYWpm+++Uaurq6aNGmSOnXqpJ9++knu7u6SpMTERPn6+iohIeGa1xATE6OuXbvq8OHDCg0NlST99ttv2rhxo/nt8z4+Ppo3b55CQkK0a9cu9e/fXz4+Pho+fHih711cXJz27NmjhQsXKiQkREuXLlWnTp20a9cu1apVS7Gxsbp48aI2btwob29v7dmzR2XKlCn0+QBIMgDgH4qKijK6d+9urrdt29Zo06aNXZ8WLVoYI0aMMNclGUuXLrXr0759e+OVV16xa/voo4+MihUrGoZhGKtWrTJcXV2N5ORkc3tCQoLdsT766COjTp06Rm5urtknKyvL8PLyMtasWWPWGxQUZGRlZV33urKzs41KlSoZY8eONdtGjx5tVK1a1cjJybnqPq+//rrRrFkzc33s2LFG48aNzfW2bdsagwcPttune/fuRlRUlGEYhnH48GHDxcXFOH78uF2f9u3bG6NGjTIMwzAaNmxojBs37rq1A7gxjBABKBaNGjWyW69YsaLS0tKuu8/OnTu1adMmvfzyy2ZbTk6OLly4oPPnz2vfvn2qUqWKgoODze133nlnvmMcOHBAPj4+du0XLlzQwYMHzfWGDRuao0XX4uLioqioKM2bN09jx46VYRiaP3++oqOjVarU5RkHixYt0owZM3Tw4EFlZmYqOztbvr6+1z3u9ezatUs5OTmqXbu2XXtWVpbKlSsnSRo0aJCefvpprV27VuHh4erVq1e++w3gxhCIABQLNzc3u3Wbzabc3Nzr7pOZmanx48erZ8+e+bZ5enoW6LyZmZlq1qyZPvnkk3zbKlSoYP63t7d3gY73xBNPKD4+XuvWrVNubq6OHj2q6OhoSVJSUpIiIyM1fvx4RUREyM/PTwsXLtSUKVOuebxSpUrJMAy7tr/OOcrMzJSLi4u2bdtmfpSYJ+9jsSeffFIRERFasWKF1q5dq/j4eE2ZMkXPPvtsga4JQH4EIgAO4ebmppycHLu2pk2bat++fapZs+ZV96lTp46OHj2q1NRUBQUFSZK2bNmS7xiLFi1SYGDgPxqpyVOjRg21bdtWH3zwgQzDUHh4uDmf6LvvvlNoaKhefPFFs//hw4eve7wKFSooOTnZXM/JydHPP/+se++9V5J0xx13KCcnR2lpabr77ruveZwqVaroqaee0lNPPaVRo0bpvffeIxAB/wBPmQFwiGrVqikxMVEpKSn6888/JUljxozRhx9+qPHjx2v37t365ZdftHDhQr300kuSpA4dOqhGjRqKiorSTz/9pE2bNpnbbDabJCkyMlLly5dX9+7d9c033+jQoUP6+uuvNWjQIB07dqxQtcbExGjJkiVaunSpYmJizPZatWrpyJEjWrhwoQ4ePKgZM2Zo6dKl1z3WfffdpxUrVmjFihXau3evnn76aZ05c8bcXrt2bUVGRqpv375asmSJDh06pB9++EHx8fFasWKFJGnIkCFas2aNDh06pO3bt2v9+vWqV69eoa4NwGUEIgAOMWXKFCUkJKhKlSq64447JEkRERFavny51q5dqxYtWqhVq1aaNm2aOSLj4uKiL774QpmZmWrRooWefPJJc3Qm7yO10qVLa+PGjapatap69uypevXqKSYmRhcuXCj0iFGvXr3k4eGh0qVL272A8oEHHtBzzz2nuLg4NWnSRN99951Gjx593WM98cQTioqKUt++fdW2bVvddttt5uhQnrlz56pv374aNmyY6tSpox49emjLli2qWrWqpMujSrGxsapXr546deqk2rVra9asWYW6NgCX2YwrP8wGgJvIpk2b1KZNGx04cEA1atRwdDkAblIEIgA3laVLl6pMmTKqVauWDhw4oMGDB6ts2bL69ttvHV0agJsYk6oB3FTOnj2rESNG6MiRIypfvrzCw8Ov+1QXABQEI0QAAMDymFQNAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAsj0AEAAAs7/8BFujUi7YS8qEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "result_labels = [int(num) for num in result_labels]\n",
    "\n",
    "# Display the distribution of integer values\n",
    "plt.hist(result_labels, bins=range(min(result_labels), max(result_labels) + 2), align='left')\n",
    "plt.xlabel('Integer Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Integer Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame({\n",
    "    'id': df['id'],\n",
    "    'label': result_labels\n",
    "})\n",
    "\n",
    "# Exporting to a jsonl file\n",
    "new_df.to_json('datasets/subtask_b.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
