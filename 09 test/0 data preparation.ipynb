{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    18000 non-null  object\n",
      " 1   id      18000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_json('datasets/subtaskA_test_monolingual.jsonl', lines=True)\n",
    "df= pd.read_json('datasets/subtaskB_test.jsonl', lines=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Driverless vehicles are becoming more commonpl...</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13270</th>\n",
       "      <td>The \"face on Mars\" is at the center of controv...</td>\n",
       "      <td>13270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>The use of technology to monitor students' em...</td>\n",
       "      <td>5281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16889</th>\n",
       "      <td>In the arcticle it states how driverless cars ...</td>\n",
       "      <td>16889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>Now that everyone has a cell phone, usage whil...</td>\n",
       "      <td>5032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     id\n",
       "923    Driverless vehicles are becoming more commonpl...    923\n",
       "13270  The \"face on Mars\" is at the center of controv...  13270\n",
       "5281    The use of technology to monitor students' em...   5281\n",
       "16889  In the arcticle it states how driverless cars ...  16889\n",
       "5032   Now that everyone has a cell phone, usage whil...   5032"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision-making is one of life's most difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When you think of voting for president, do you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driverless Cars - Limitations &amp; Potential Draw...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There are multiple benefits to attending high ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Electoral College, also known as the Presi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id\n",
       "0  Decision-making is one of life's most difficul...   0\n",
       "1  When you think of voting for president, do you...   1\n",
       "2  Driverless Cars - Limitations & Potential Draw...   2\n",
       "3  There are multiple benefits to attending high ...   3\n",
       "4  The Electoral College, also known as the Presi...   4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    18000.000000\n",
       "mean      2381.772833\n",
       "std       1027.617891\n",
       "min         76.000000\n",
       "25%       1729.000000\n",
       "50%       2405.000000\n",
       "75%       2864.000000\n",
       "max      17000.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_length'] = df['text'].apply(len)\n",
    "df['text_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghiki\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import EarlyStoppingCallback,AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.special import softmax\n",
    "import argparse\n",
    "import logging\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import wandb\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textstat.textstat import textstatistics\n",
    "import pandas as pd\n",
    "import language_tool_python\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ghiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Ghiki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Initialize the grammar checker\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "\n",
    "def extract_text_features(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(sentences)\n",
    "\n",
    "    # Lexical diversity\n",
    "    unique_words = set(words)\n",
    "    lexical_diversity = len(unique_words) / word_count\n",
    "\n",
    "    # Average sentence length\n",
    "    avg_sentence_length = word_count / sentence_count\n",
    "\n",
    "    # Average word length\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count\n",
    "\n",
    "    # Lexical density\n",
    "    tags = nltk.pos_tag(words)\n",
    "    content_words = [word for word, tag in tags if tag.startswith(('N', 'V', 'J', 'R'))]\n",
    "    lexical_density = len(content_words) / word_count\n",
    "\n",
    "    # Readability scores\n",
    "    flesch_reading_ease = textstatistics().flesch_reading_ease(text)\n",
    "    fog_index = textstatistics().gunning_fog(text)\n",
    "\n",
    "    # Grammatical errors\n",
    "    matches = tool.check(text)\n",
    "    grammatical_errors = len(matches)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    return pd.Series({\n",
    "        'word_count': word_count,\n",
    "        'sentence_count': sentence_count,\n",
    "        'lexical_diversity': lexical_diversity,\n",
    "        'avg_sentence_length': avg_sentence_length,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'lexical_density': lexical_density,\n",
    "        'flesch_reading_ease': flesch_reading_ease,\n",
    "        'gunning_fog_index': fog_index,\n",
    "        'grammatical_errors': grammatical_errors\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34272/34272 [44:22<00:00, 12.87it/s]  \n",
      "100%|██████████| 18000/18000 [21:25<00:00, 14.00it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df= pd.read_json('datasets/subtaskA_test_monolingual.jsonl', lines=True)\n",
    "test_df= pd.read_json('datasets/subtaskB_test.jsonl', lines=True)\n",
    "features_df = df['text'].progress_apply(extract_text_features)\n",
    "features_df_test = test_df['text'].progress_apply(extract_text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammatical_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>542.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.464945</td>\n",
       "      <td>17.483871</td>\n",
       "      <td>4.077491</td>\n",
       "      <td>0.512915</td>\n",
       "      <td>80.72</td>\n",
       "      <td>8.14</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>464.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>20.173913</td>\n",
       "      <td>5.202586</td>\n",
       "      <td>0.575431</td>\n",
       "      <td>28.13</td>\n",
       "      <td>14.96</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.464158</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>17.17</td>\n",
       "      <td>16.62</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>442.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.604072</td>\n",
       "      <td>27.625000</td>\n",
       "      <td>5.615385</td>\n",
       "      <td>0.581448</td>\n",
       "      <td>12.56</td>\n",
       "      <td>18.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1080.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.323148</td>\n",
       "      <td>21.176471</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>52.19</td>\n",
       "      <td>10.52</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34267</th>\n",
       "      <td>371.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>24.733333</td>\n",
       "      <td>4.175202</td>\n",
       "      <td>0.582210</td>\n",
       "      <td>59.43</td>\n",
       "      <td>11.18</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34268</th>\n",
       "      <td>383.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.464752</td>\n",
       "      <td>25.533333</td>\n",
       "      <td>4.885117</td>\n",
       "      <td>0.519582</td>\n",
       "      <td>49.25</td>\n",
       "      <td>12.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34269</th>\n",
       "      <td>341.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.360704</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.293255</td>\n",
       "      <td>0.539589</td>\n",
       "      <td>35.00</td>\n",
       "      <td>13.28</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34270</th>\n",
       "      <td>273.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.893773</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>77.77</td>\n",
       "      <td>9.32</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34271</th>\n",
       "      <td>452.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.504425</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>5.400442</td>\n",
       "      <td>0.557522</td>\n",
       "      <td>25.49</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34272 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  sentence_count  lexical_diversity  avg_sentence_length  \\\n",
       "0           542.0            31.0           0.464945            17.483871   \n",
       "1           464.0            23.0           0.551724            20.173913   \n",
       "2           558.0            18.0           0.430108            31.000000   \n",
       "3           442.0            16.0           0.604072            27.625000   \n",
       "4          1080.0            51.0           0.323148            21.176471   \n",
       "...           ...             ...                ...                  ...   \n",
       "34267       371.0            15.0           0.528302            24.733333   \n",
       "34268       383.0            15.0           0.464752            25.533333   \n",
       "34269       341.0            11.0           0.360704            31.000000   \n",
       "34270       273.0            13.0           0.564103            21.000000   \n",
       "34271       452.0            20.0           0.504425            22.600000   \n",
       "\n",
       "       avg_word_length  lexical_density  flesch_reading_ease  \\\n",
       "0             4.077491         0.512915                80.72   \n",
       "1             5.202586         0.575431                28.13   \n",
       "2             5.464158         0.569892                17.17   \n",
       "3             5.615385         0.581448                12.56   \n",
       "4             4.625000         0.555556                52.19   \n",
       "...                ...              ...                  ...   \n",
       "34267         4.175202         0.582210                59.43   \n",
       "34268         4.885117         0.519582                49.25   \n",
       "34269         5.293255         0.539589                35.00   \n",
       "34270         3.893773         0.527473                77.77   \n",
       "34271         5.400442         0.557522                25.49   \n",
       "\n",
       "       gunning_fog_index  grammatical_errors  \n",
       "0                   8.14                 6.0  \n",
       "1                  14.96                 1.0  \n",
       "2                  16.62                 3.0  \n",
       "3                  18.99                 0.0  \n",
       "4                  10.52                 4.0  \n",
       "...                  ...                 ...  \n",
       "34267              11.18                15.0  \n",
       "34268              12.65                 0.0  \n",
       "34269              13.28                 0.0  \n",
       "34270               9.32                31.0  \n",
       "34271              15.63                 0.0  \n",
       "\n",
       "[34272 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammatical_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>4.273973</td>\n",
       "      <td>0.534247</td>\n",
       "      <td>64.30</td>\n",
       "      <td>9.84</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>806.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.356079</td>\n",
       "      <td>26.866667</td>\n",
       "      <td>4.204715</td>\n",
       "      <td>0.508685</td>\n",
       "      <td>66.98</td>\n",
       "      <td>9.72</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>5.232258</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>33.78</td>\n",
       "      <td>18.19</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.258517</td>\n",
       "      <td>26.263158</td>\n",
       "      <td>4.709419</td>\n",
       "      <td>0.631263</td>\n",
       "      <td>48.33</td>\n",
       "      <td>11.34</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>369.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.466125</td>\n",
       "      <td>23.062500</td>\n",
       "      <td>4.457995</td>\n",
       "      <td>0.506775</td>\n",
       "      <td>58.82</td>\n",
       "      <td>11.44</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>639.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.431925</td>\n",
       "      <td>22.821429</td>\n",
       "      <td>4.244131</td>\n",
       "      <td>0.528951</td>\n",
       "      <td>67.08</td>\n",
       "      <td>11.13</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>464.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.463362</td>\n",
       "      <td>24.421053</td>\n",
       "      <td>5.068966</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>32.53</td>\n",
       "      <td>14.68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>235.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.804255</td>\n",
       "      <td>21.363636</td>\n",
       "      <td>4.706383</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>53.61</td>\n",
       "      <td>10.83</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>530.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.477358</td>\n",
       "      <td>24.090909</td>\n",
       "      <td>5.658491</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>15.81</td>\n",
       "      <td>15.63</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>642.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.342679</td>\n",
       "      <td>26.750000</td>\n",
       "      <td>4.091900</td>\n",
       "      <td>0.503115</td>\n",
       "      <td>71.48</td>\n",
       "      <td>11.14</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_count  sentence_count  lexical_diversity  avg_sentence_length  \\\n",
       "0           219.0            10.0           0.794521            21.900000   \n",
       "1           806.0            30.0           0.356079            26.866667   \n",
       "2           155.0             5.0           0.903226            31.000000   \n",
       "3           499.0            19.0           0.258517            26.263158   \n",
       "4           369.0            16.0           0.466125            23.062500   \n",
       "...           ...             ...                ...                  ...   \n",
       "17995       639.0            28.0           0.431925            22.821429   \n",
       "17996       464.0            19.0           0.463362            24.421053   \n",
       "17997       235.0            11.0           0.804255            21.363636   \n",
       "17998       530.0            22.0           0.477358            24.090909   \n",
       "17999       642.0            24.0           0.342679            26.750000   \n",
       "\n",
       "       avg_word_length  lexical_density  flesch_reading_ease  \\\n",
       "0             4.273973         0.534247                64.30   \n",
       "1             4.204715         0.508685                66.98   \n",
       "2             5.232258         0.625806                33.78   \n",
       "3             4.709419         0.631263                48.33   \n",
       "4             4.457995         0.506775                58.82   \n",
       "...                ...              ...                  ...   \n",
       "17995         4.244131         0.528951                67.08   \n",
       "17996         5.068966         0.525862                32.53   \n",
       "17997         4.706383         0.574468                53.61   \n",
       "17998         5.658491         0.603774                15.81   \n",
       "17999         4.091900         0.503115                71.48   \n",
       "\n",
       "       gunning_fog_index  grammatical_errors  \n",
       "0                   9.84                 4.0  \n",
       "1                   9.72                26.0  \n",
       "2                  18.19                 3.0  \n",
       "3                  11.34                 2.0  \n",
       "4                  11.44                 3.0  \n",
       "...                  ...                 ...  \n",
       "17995              11.13                 9.0  \n",
       "17996              14.68                 0.0  \n",
       "17997              10.83                 5.0  \n",
       "17998              15.63                 0.0  \n",
       "17999              11.14                 7.0  \n",
       "\n",
       "[18000 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('datasets/features_df_test_A.csv', index=False)\n",
    "features_df_test.to_csv('datasets/features_df_test_B.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
